---
title: "Modeling Central Park Weather and Human Activity"
author: "Team 4: Chris, Tejas, Emily"
date: "`r Sys.Date()`"
output:
  html_document:
    theme: paper
    code_folding: hide
    number_sections: false
    toc: yes
    toc_depth: 3
    toc_float: yes
  pdf_document:
    toc: yes
    toc_depth: '3'
---

```{r include=FALSE}
# The package "ezids" (EZ Intro to Data Science) includes a lot of the helper functions we developed for the course. 
# Some of the frequently used functions are loadPkg(), xkabledply(), xkablesummary(), uzscale(), etc.
library(ezids)
 
# some of common options (and the defaults) are: 
# include=T, eval=T, echo=T, results='hide'/'asis'/'markup',..., collapse=F, warning=T, message=T, error=T, cache=T, fig.width=6, fig.height=4, fig.dim=c(6,4) #inches, fig.align='left'/'center','right', 
# knitr::opts_chunk$set(warning = F, results = "markup", message = F)
knitr::opts_chunk$set(warning = F, results = "hide", message = F, echo = F)
options(scientific=T, digits = 3) 
# options(scipen=9, digits = 3) 
# ‘scipen’: integer. A penalty to be applied when deciding to print numeric values in fixed or exponential notation.  Positive values bias towards fixed and negative towards scientific notation: fixed notation will be preferred unless it is more than ‘scipen’ digits wider.
# use scipen=999 to prevent scientific notation at all times
```

```{r data init}
#loading packages 
library(ezids)
library(ggplot2)
library(ggrepel)
library(gridExtra)
library(tibble)
library(dplyr)
library(tidyr)
library(psych)
library(corrplot)
library(lattice)
library(FNN)
library(caret)
library(pROC)

#loading data 
NYweath <- data.frame(read.csv("data/NYC_weather_1869_2022.csv"))

#converting to R date format and adding columns for day, month, and year
NYweath$DATE <- as.Date(NYweath$DATE)
NYweath$day <- format(NYweath$DATE, format="%d")
NYweath$month <- format(NYweath$DATE, format="%m")
NYweath$year <- format(NYweath$DATE, format="%Y")
#converting temperature observations to numerical
NYweath$TMAX <- as.numeric(NYweath$TMAX)
NYweath$TMIN <- as.numeric(NYweath$TMIN)
NYweath$TAVG <- as.numeric(NYweath$TAVG)
NYweath$year <- as.numeric(NYweath$year)
#Making month a factor
NYweath$month <- as.factor(NYweath$month)
# subset data to desired variables
NYweath_sub <- subset(NYweath, select = c(DATE, day, month, year, TMAX, TMIN, TAVG, PRCP, SNOW)) 
#creating a subset for 1900 on
NYweath_00 <- subset(NYweath_sub, year > 1899)
xkabledplyhead(NYweath_00)


#new data loading from Emily, New York State population from 1900 on 
NYSPop_1900 <- data.frame(read.csv("data/NYSPop_1900-2021.csv"))
NYSPop_1900$Population <- as.numeric(NYSPop_1900$Population)
NYSPop_1900$Year <- as.numeric(NYSPop_1900$Year)

#creating a subset for 1900-2021
NYweath_00a <- subset(NYweath_sub, year > 1899)
NYweath_00a <- subset(NYweath_00a, year < 2022)

for(i in 1:length(NYweath_00a$year)){
  (NYweath_00a$Pop[i]= NYSPop_1900$Population[(which(NYSPop_1900$Year == NYweath_00a$year[i]))]
  )}

#New data loading from Emily, shootings
NYshoot <- data.frame(read.csv("data/Shooting_Counts_ERG.csv"))

#converting to R date format and adding columns for day, month, and year
NYshoot$DATE <- as.Date(NYshoot$Date, format = "%m/%d/%Y")

#cleaning shooting data, merging with NYweath_00a
NYweathshoot_06 <- subset (NYweath_00a, year > 2005)
NYweathshoot_06 <- subset (NYweathshoot_06, year < 2022)

NYweathshoot_06 <- full_join(NYshoot, NYweathshoot_06, by = "DATE")
NYweathshoot_06$day <- format(NYweathshoot_06$DATE, format="%d")
NYweathshoot_06$month <- format(NYweathshoot_06$DATE, format="%m")
NYweathshoot_06$year <- format(NYweathshoot_06$DATE, format="%Y")
NYweathshoot_06$day <- as.numeric(NYweathshoot_06$day)
NYweathshoot_06$month <- as.factor(NYweathshoot_06$month)
NYweathshoot_06$year <- as.numeric(NYweathshoot_06$year, format="%Y")

#Note: there are no NAs for shootings-- but the way I extracted the data, zeros were not included, so I have to add them back in where NAs currently are.
NYweathshoot_06 <- NYweathshoot_06 %>% mutate(Shootings = ifelse(is.na(Shootings), 0, Shootings))
summary(NYweathshoot_06)
```


```{r}
##CW ADD: Adding a 'TOT_PRCP' row that sums up the total precipitation between SNOW and PRCP. This row will be used in Question 3.

NYweath_final <- NYweath_00
NYweath_final$TOT_PRCP <- NYweath_00$PRCP + NYweath_00$SNOW

```


# Introduction  

In our first project, we analyzed daily weather patterns from data collected at a weather station in Central Park, New York City made available online by the National Oceanic and Atmospheric Administration. Through our analysis, we confirmed that there was a statistically significant rise in daily maximum temperatures in Central Park over the last 122 years.  

We performed an ANOVA test on daily maximum temperature values over different periods of time and found statistically significant results regarding variance in-between our samples. This led us to create linear models for the change in daily maximum temperature over time, revealing statistically significant warming at an average rate of about 0.025 degrees Fahrenheit per year from 1900-2022. This is in fact a larger increase in temperature than the average global warming trend reported by [INSERT ORGANISATION NAME HERE!] (an average of 0.014 degrees Fahrenheit per year). However, since 1982, average temperatures in Central Park have increased significantly less than average global warming, perhaps because much of the development in New York City took place during the first half of the century.  

We had more questions about relationships between weather and human activity, which are explored here in our Final Project.  


## Our Research Questions

For this project, we looked more directly at correlations between human activity and weather by incorporating new datasets related to population, air quality, crime (shootings and arrests), the stock market, and COVID-19.  

1. Do changes in Central Park maximum daily temperatures also correlate to measures of human activity?  
2. Are there statistically measurable changes in NYC air quality over time, and are they correlated to changes in daily maximum temperature observed in previous analysis?  
3. How do daily weather patterns correlate to other local human activity, such as crime, reported COVID cases, and stock market performance?  

# Central Park Warming and Human Activity

We developed several linear models of Central Park warming over time in Project 1 using all daily TMAX observations between 1900 and 2022. We observed statistically significant correlations between month (as a categorial variable), reflecting seasonal temperature variations, and year (as a numeric variable), reflecting a longer-term warming trend. 

The resulting fit (using all daily data) has an $R^2$ value of 0.775 and a slope of 0.025 degrees Fahrenheit per year, with all fit parameters' p-values well below 0.05. The different intercepts for the each level of the categorical variable (the twelve months of the year) indicated that January is the coldest and July the hottest month in Central Park, with an average difference in maximum daily temperature of approximately 46 degrees Fahrenheit in any given year over this window.  


```{r}
#LM1 for 1900-2022
maxTfit00_ym <- lm(formula = TMAX ~ year + month, data = NYweath_00a )
res00_ym <- residuals(maxTfit00_ym)
summary(maxTfit00_ym)  

```

The two extremes and their linear models are plotted again here to illustrate the quality of fit.  


```{r}
#plot of just July and January

ggplot(NYweath_00a, aes(x = year, y = TMAX, color = month)) +
    geom_point() +
    scale_color_manual(values = c("01" = "purple4",
                                   "07" = "red"), na.value = NA) +
    geom_abline(aes(intercept = -11.05508, slope = 0.02539), col = "black", size = 1) + 
    geom_abline(aes(intercept = 34.98295, slope = 0.02539), col = "black", size = 1) +
    labs(
        x = "Year",
        y = "Maximum Daily Temperature",
        title = "Maximum Daily Temperature in Central Park") +
    xlab(label = "Year") +
    ylab(label = "Maximum daily temperature") +
    ggtitle(label = "Maximum Daily Temperature in Central Park")
```

However, we expect that time is just a proxy for the cause: human activity-- namely, construction in the local environment using materials that hold more heat than the natural environment (EPAb 2022), and increased consumption of energy and materials that release greenhouse gases over the course of their life cycle.  We wanted to explore correlations with other, more direct proxies for human activity. 

We sought other data sources related to these trends, for example local economic data (New York GDP), construction (sector revenue or number of new sites), New York City population, and local GHG emissions. While we found some sources for most of these, unfortunately none extended more than 50 years into the past with daily or annual observations except one: annual New York State population data (obtained from Macrotrends.com). Because this source was unknown, we validated the reported value for each decade against the corresponding data from the U.S. Census (it appears that values for intervening years were interpolated somehow).

We then recreated a new linear model for TMAX (for 1900-2021 due to range of population data), attempting to use New York State `population` instead of year: 'TMAX ~ population + month'.   


```{r}
#LM2
maxTfit00_pop <- lm(formula = TMAX ~ Pop + month, data = NYweath_00a)
summary(maxTfit00_pop)  

```

While we do observe a significant correlation -- the p-value of the model's `population` coefficient is well below the cutoff of alpha = 0.05) -- the fit appears not to be any better than the regression against year. This caused us to wonder if a fit using month alone would be better than a fit using `month` or `year`, or `population` or `year`.  


```{r}
#LM1
maxTfit00_m <- lm(formula = TMAX ~ month, data = NYweath_00a)
summary(maxTfit00_m)  

```

```{r}
#anova(maxTfit00_m, maxTfit00_ym)
```

```{r}
#anova(maxTfit00_all, maxTfit00_all)
```


The $R^2$ value is a bit lower (though not much: 0.771 v. 0.773). To assess whether the model is distinct from those also including `population` or `year`, we ran ANOVA tests on each pair of nested models. According to the tests, the models are in fact significantly different (p-values of the chi-squared fits were well below an alpha of 0.05).  

Nonetheless, given that the data are partially interpolated values and that we are looking at subtle, long-term trends over only 122 years at a single location-- and that climate change is a complicated, average, and distributed phenomenon-- we have probably exhausted our ability to build climate change models based solely on Central Park data.  

For fun, we looked for correlations between temperature and other weather variables between 1900 and 2022.  

```{r}
NYweath_cor <- subset(NYweath_00, select = c(year, TMAX, PRCP, SNOW))
str(NYweath_cor)
weathcor <- cor(NYweath_cor, use = "pairwise.complete.obs")
corrplot::corrplot(weathcor)
cor

```

We do see some correlation between `TMAX` and `SNOW`, and so add this into the model (`TMAX ~ year + month + SNOW`). This is slightly improved (with all coefficients' p-values well below 0.05): year, month, and whether it is snowing appear to account for 77.6% ($R^2 = 0.776) of the variability of in daily maximum temperature in Central Park. (However, we note that 96 NAs for `SNOW` had to be removed to develop the model, so this result is likely not directly comparable to the other models). We also considered additional local environmental correlations, described in the next section.  

```{r}
#LM4
maxTfit00_all <- lm(formula = TMAX ~ year + month + SNOW, data = NYweath_00a)
summary(maxTfit00_all)  

```


# Local Weather and Air Quality

The Air Quality Index (AQI) is used for daily reporting of local air quality. It tells us how clean or polluted the air is, and what associated health effects might be a concern for the public. The higher the AQI value, the the greater the level of air pollution and greater the health concern. Outdoor concentrations of pollutants such as ozone, carbon monoxide, nitrogen dioxide, sulfur dioxide, and PM2.5/PM10 concentrations are measured at stations across New York City and reported to the EPA. The daily AQI is calculated based on these concentration values and stored within the EPA's Air Quality System database. 

Changes in urban life correlate with changes in air quality within that urban area. Sources of emissions such as traffic and burning of fossil fuels for energy generation can cause air quality to deteriorate. Emissions can also contribute to global warming by releasing more greenhouse gasses into the atmosphere, thus increasing average temperatures. As more people migrate to urban areas, we will continue to see a deterioration in air quality unless reducing measures are taken. Our goal for integrating this data is to study the affects of weather patterns on air quality, and to statistically verify changes in air quality over time in New York City.  

The dataset contains about 7,000 observations collected from January, 2000 to October, 2022.  

```{r load air quality data, echo=F}
# Load data and view structure
DailyAQ_00_22 <- data.frame(read.csv("data/daily-AQ-NY-00-20.csv"))
DailyAQ_00_22 <- DailyAQ_00_22[c('Date', 'DAILY_AQI_VALUE')]
colnames(DailyAQ_00_22) <- c('DATE', 'AQI')
str(DailyAQ_00_22)
xkablesummary(DailyAQ_00_22)
xkabledplyhead(DailyAQ_00_22)
```


```{r formatting, echo=F}
# format variables
DailyAQ_00_22$DATE <- as.Date(DailyAQ_00_22$DATE, "%m/%d/%y")

DailyAQ_00_22$year = as.numeric(format(DailyAQ_00_22$DATE, "%Y"))

DailyAQ_00_22_Yearly_Growth <- DailyAQ_00_22 %>%
  group_by(year) %>%
  summarize(aqi_total = sum(AQI, na.rm=T),
            aqi_avg = mean(AQI, na.rm=T))

DailyAQ_00_22_Yearly_Growth <- DailyAQ_00_22_Yearly_Growth %>%
  mutate(aqi_diffRate = ((aqi_avg - lag(aqi_avg)) / aqi_avg) * 100)

```

We start by looking at the distribution of our variable of interest: AQI.

```{r daily aqi plots, results='asis'}
# distribution plot of pmi2.5 and daily AQI
mean_aqi <- mean(DailyAQ_00_22$AQI)

ggplot(DailyAQ_00_22) +
  geom_histogram(aes(x=AQI), na.rm=TRUE, alpha=0.5, color="black", fill='#2DD164', bins=50, binwidth=5) +
  geom_vline(xintercept=mean_aqi, color="black", size=1, linetype=5, show.legend=FALSE) +
  annotate("text", x=mean_aqi + 9, y=625, label=paste(round(mean_aqi, 2)), angle=0, size=4, color="black") +
  labs(title="Distribution of Daily AQI Level", x="", y="Count")

```

From the histogram above, we can gauge that the distribution is slightly right-skewed. With the large number of observations in our dataset, we can assume normality for our modeling. The right-skewness is caused by days with unusually high AQI values.  

The year-over-year growth rate was also calculated based on yearly average AQI and is depicted in the line plot below.  

```{r year-over-year rate, results='asis'}
ggplot(DailyAQ_00_22_Yearly_Growth, aes(group=1)) +
  geom_line(aes(x = year, y = aqi_diffRate), na.rm = T, stat="identity", color="#043008", size=1) +
  geom_point(aes(x = year, y = aqi_diffRate), na.rm = TRUE, fill="#E6E930", shape = 23) +
  labs(title="AQI year-over-year rate in NYC", x="Year", y="AQI") +
  theme(
    axis.title.y = element_text(color = "#043008", size = 13),
    axis.title.y.right = element_text(color = "#E6E930", size = 13)
  )
```

We can see an alternating patterns of increase and decrease in average AQI between each year from 2000 to 2009. After 2009, the pattern is broken but the variance continues.  

In order to evaluate correlation between weather and air quality, we combined our dataset with the NYC weather data based on the date value in each. Dates without a matching air quality measurement are dropped. Subsequent models will be built using this merged dataframe.
 
```{r combine and clean data}
# merge data frame by date
DailyAQ_merged <- merge(DailyAQ_00_22, NYweath_00, by="DATE")
# select required columns
DailyAQ_merged <- DailyAQ_merged[ , c('DATE', 'year.x', 'month', 'AQI', 'TMAX', 'TMIN', 'PRCP', 'SNOW')]
colnames(DailyAQ_merged)[2] <- "year"
str(DailyAQ_merged)
xkablesummary(DailyAQ_merged)
```

The first step to building linear models is assessing correlation between numerical variables in the data. Because the year variable in our dataset begins at 2000, it will unnecessarily scale our coefficients when used in linear modeling. Therefore, we scaled the variable to start at 0 (and continue to 22 to represent 2022).  

The correlation is evaluated via a pairs plot, which depicts the correlation coefficient between numerical variables, and includes scatterplots of their relationships. The pairs plot uses the Pearson correlation method.

```{r data prep}
# subset to numerical variables
DailyAQ_numerics <- DailyAQ_merged[ , c('AQI', 'TMAX', 'TMIN', 'PRCP', 'SNOW', 'year')]
DailyAQ_numerics$year <- DailyAQ_numerics$year - 2000 
```


```{r pairs}
pairs.panels(DailyAQ_numerics, 
  method = "pearson", # correlation method
  hist.col = "red", # set histogram color
  density = TRUE,  # show density plots
  ellipses = TRUE, # show correlation ellipses
  smoother = TRUE,
  lm = TRUE,
  main = "Pairs Plot Of Weather and Air Quality Numerical Variables",
  cex.labels=0.75
)
```

From the pearson pairsplot above, we can see a moderately high, negative correlation value between year and AQI. This indicates that as the year increases, the AQI is actually dropping resulting in better air quality in the city. 

To better observe the effects of year on AQI, we can visualize the yearly average AQI.

```{r AQI vs year}
# yearly average and year-over year growth of daily AQI and PM2.5
ggplot(DailyAQ_00_22_Yearly_Growth) +
  geom_line(aes(x = year, y = aqi_avg), stat="identity", color="#2DD164", size=1) +
  geom_point(aes(x = year, y = aqi_avg), na.rm = TRUE, fill="#457108", shape = 21) +
  labs(title="Average AQI by year in NYC", x="Year", y="AQI value")
```

The line plot confirms the correlation value we observed in the pairs plot. The average yearly AQI is indeed decreasing as year increases. Next, we build a linear model using year as a regressor to estimate daily AQI.  

```{r linear model}
aqi_fit <- lm(AQI ~ year, data = DailyAQ_numerics)
summary(aqi_fit)
xkabledply(aqi_fit, title = paste("First Linear Model: ", format( formula(aqi_fit) )))
```

The results of our linear model reveal a significant value for both the intercept and year coefficient. The coefficient value for the year regressor indicates that for every year increase, the predicted daily AQI decreases by a factor of 1.78. This supports the correlation coefficient we saw earlier between these two variables. The p-value of the F-statistic is also significant, but the $R^2$ value of the model is a measly 0.28. Based on this model, the year only explains 28% of the variability in daily AQI measurements. This is not a significantly high result. Looking at the scatterplot of the relationship can help explain the weak fit.

```{r lm plot}
ggplot(DailyAQ_00_22, aes(x = year, y = AQI)) + 
  geom_point(alpha = 0.5, color = "#2DD164", position = "jitter") +
  labs(x = "Year", y = "AQI Value", title = "Daily AQI Values From 2000-2022 With Trend Line") +
  geom_smooth(method = 'lm', formula = 'y ~ x', color = "black", fill="black")
```

As we can see, there is a high degree of noise when observing daily AQI values at the yearly level. Although the plot displays a slightly downward trend in daily AQI, but model fit is distorted. This helps explain the results we received from our linear model.  
Can we add more or different predictors to improve the fit? In our first project, we looked at linear trends of TMAX over time and determined a slight positive correlation observed over the years 1900-2022. We also utilized month as a categorical regressor to help explain the variance in daily maximum temperatures. Based on those results, we concluded that seasonality trends had a negative impact on model performance. Perhaps seasonality also also plays a part in daily AQI measurements.  

```{r average AQI and TMAX vs year}
# NYC weather - Avg TMAX by month
NYweath_Monthly_Avg <- NYweath_00 %>%
  group_by(month) %>%
  summarize(avg_max_temp = mean(TMAX, na.rm=T),
            avg_min_temp = mean(TMIN, na.rm=T))


ggplot(NYweath_Monthly_Avg, aes(x = as.numeric(month), y = avg_max_temp)) +
  geom_line(color="#F21E1E", size = 2) +
  geom_point(na.rm = TRUE, fill="#126BF4", shape = 21, size = 4) +
  labs(title="Average TMAX By Month in NYC", x="Month", y="Temperature (°F)") +
  scale_x_continuous(name = "Month",
                     breaks = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12))
```

To refresh our memories, we included the monthly average daily maximum temperature. A seasonal trend can be observed as temperatures increase during summer months and decrease during winter months.

```{r monthly average AQI}
DailyAQ_monthly <- DailyAQ_merged %>%
  group_by(month) %>%
  summarize(aqi_avg = mean(AQI, na.rm=T))


# monthly average AQI
ggplot(DailyAQ_monthly, aes(x = as.numeric(month), y = aqi_avg)) +
  geom_line(color="#47ABE9", size = 2) +
  geom_point(na.rm = TRUE, fill="#C10808", shape = 21, size = 4) +
  labs(title="Average AQI By Month in NYC", x="Month", y="AQI") +
  scale_x_continuous(name = "Month",
                     breaks = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12))
```

Plotting the average AQI by month, we observe seasonal trends. AQI values are generally high during winter and summer months, but realtively low for the the months in between.  

Based on this, we modify our last model and attempt to fit seasonality by adding `month` as a categorical regressor, along with our variable-of-interest from the last project - `TMAX`.

```{r second linear model}
aqi_fit2 <- lm(AQI ~ TMAX + month, data = DailyAQ_merged)
summary(aqi_fit2)
xkabledply(aqi_fit2, title = paste("Second Linear Model: ", format( formula(aqi_fit2) )))
```

The regression coefficient for `TMAX` is significant and positively correlated, with each degree Fahrenheit increase resulting in AQI increasing by a factor of 0.68. The regression coefficients for all month categories are also significant. In fact, every month has a negative impact on AQI when compared to January. September exhibits the largest difference, with a predicted AQI almost 44 points lower than January!  

The p-value of the model's F-statistic is also significant, concluding a significant relationship between our chosen predictors and the daily AQI value. However, the $R^2$ for our model is only `.149`, which is weaker than our previous model. This indicates that only 14.7% of the variation in daily AQI can be explained by `TMAX` and `month`.  

```{r model 1 VIF}
# model VIF scores
xkablevif(aqi_fit2, title = "Model 2 VIF")
```

The VIF scores for all regressors are in an acceptable range, however the fit is still poor. It seems that due to seasonal nature of our time-series data, we cannot properly model daily AQI using linear regression. Perhaps a classification technique can be utilized to address the seasonal trends. More precisely, we can build a kNN model to classify the month based on daily AQI and maximum temperature values.  
  
We start with plotting the relationship between our chosen predictors and add a layer to discern month within the plot.
  
```{r scatter plots, results='asis'}
ggplot(DailyAQ_merged) +
    geom_point(aes(x=AQI, y=TMAX, color=month), alpha = 0.7) +
    labs(title = "TMAX vs AQI Value Colored By Month",
         x = "Daily AQI Value",
         y = "Daily Maximum Temperature (F)") +
  scale_color_brewer(palette = "Paired")
```

We can make out minimal distinction of month from the scatterplot above, but the model will provide a more detailed analysis.  

The first step involves scaling and centering our predictor values, as they are recorded in vastly different units of measurement. We also need to split our dataset into training and testing frames. We used a 4:1 split for to satisfy this requirement.

```{r normalize data}
# center and scale our data
DailyAQ_scaled <- as.data.frame(scale(DailyAQ_merged[4:5], center = TRUE, scale = TRUE))
str(DailyAQ_scaled)
```


```{r train/test splits}
# create train and test data sets with 4:1 splits
set.seed(1000)
DailyAQ_sample <- sample(2, nrow(DailyAQ_scaled), replace=TRUE, prob=c(0.80, 0.20))

DailyAQ_training <- DailyAQ_scaled[DailyAQ_sample == 1, ]
DailyAQ_test <- DailyAQ_scaled[DailyAQ_sample == 2, ]

# create label sets.
DailyAQ_trainLabels <- DailyAQ_merged[DailyAQ_sample == 1, 3]
DailyAQ_testLabels <- DailyAQ_merged[DailyAQ_sample == 2, 3]

nrow(DailyAQ_training)
nrow(DailyAQ_test)
```


```{r evaluate for range of k}
evaluateK = function(k, train_set, val_set, train_class, val_class){
  
  # Build knn with k neighbors considered.
  set.seed(1000)
  class_knn = knn(train = train_set,    #<- training set cases
                  test = val_set,       #<- test set cases
                  cl = train_class,     #<- category for classification
                  k = k)                #<- number of neighbors considered
  
  tab = table(class_knn, val_class)
  
  # Calculate the accuracy.
  accu = sum(tab[row(tab) == col(tab)]) / sum(tab)                         
  cbind(k = k, accuracy = accu)
}

# call evaluateK function for each odd k-value between 1 to 21
knn_different_k = sapply(seq(1, 21, by = 2),
                         function(x) evaluateK(x, 
                                             train_set = DailyAQ_training,
                                             val_set = DailyAQ_test,
                                             train_class = DailyAQ_trainLabels,
                                             val_class = DailyAQ_testLabels))

# Reformat the results
knn_different_k = data.frame(k = knn_different_k[1,],
                             accuracy = knn_different_k[2,])
```

```{r accuracy vs k plot}

ggplot(knn_different_k, aes(x = k, y = accuracy)) +
  geom_line(color = "orange", size = 1.5) +
  geom_point(size = 3) + 
  labs(title = "kNN Model Accuracy vs k-value",
       x = "Model k-value",
       y = "Accuracy")
```

To find the optimal k-value, we evaluated the model over a range of k from 1 to 21. Based on the plot above, it seems 13-nearest neighbors is a decent choice as it provides the greatest improvement in predictive accuracy before the incremental improvement trails off. We can build the kNN model using 13 as the k-value.

```{r kNN model}
# set kval
kval <- 13

# build model
DailyAQ_pred <- FNN::knn(train = DailyAQ_training,
                    test = DailyAQ_test,
                    cl = DailyAQ_trainLabels,
                    k = kval)

# confusion matrix
DailyAQ_confusionMatrix <- caret::confusionMatrix(DailyAQ_pred, reference = DailyAQ_testLabels)
DailyAQ_pred_accuracy <- DailyAQ_confusionMatrix$overall['Accuracy']


xkabledply(as.matrix(DailyAQ_confusionMatrix), title = paste("ConfusionMatrix for k = ", kval))
xkabledply(data.frame(DailyAQ_confusionMatrix$byClass), title=paste("k = ", kval))
```

The overall accuracy of our model is a relatively weak value of `r DailyAQ_pred_accuracy`. This indicates that AQI and TMAX are not good predictors of month.  

```{r knn ROC/AUC, results='markup'}
# multiclass ROC on test labels
knnROC <- multiclass.roc(DailyAQ_testLabels, as.integer(DailyAQ_pred))
knnROC$auc
```
  
A multi-class ROC evaluation on the test labels yields an AUC value of 0.65, which is higher than expected based on the model's accuracy value. Still, this is not a significant result based on the AUC threshold of 0.8.  

# Local Weather and Local Human Social and Economic Activity

The last question our team set out to address is whether there are statistically significant relationship exists between local weather and local human social and economic activity. The relationship has been been explored by researchers in the past, with evidence suggesting weather has effects on an individual's mood, thermal comfort level, and social interaction and can influence traffic, travel, public health, crime rates, and even stock prices (Horanont, 2013). Our team looked to expand on this prior work by focusing on specific observations in New York City, and combining these with our weather data. We decided to look specifically at the relationship between local weather and crime rates, stock prices, and public health. 

We brought in two additional data sets to explore the relationship between weather and crime rates: data for all New York City shootings and for all New York City arrests with 5,844 observations between 2006 and 2021. Both of these data sets were available through NYC's Open Data repository (https://opendata.cityofnewyork.us/).

To interrogate the relationship between weather and on public health (beyond the air quality indicators explore in the preceding section), our team looked at COVID-19 case counts in New York City. The data were available from New York City's Open Data repository. The data set consisted of 991 observations between February 29th, 2020 and present day.

For stock market data, we looked at the total daily trade for the DOW Jones Industrial Index. These data contained 10,822 observations dating back to December 25, 1979, however trade volume was only available since 1988.


##Shootings

We found records of all reported shootings, with at least one injured victim, occurring in New York City from 2006-2021. From here we extracted the daily number of shootings (and number of these designated as murders) over the entire time period, and merged this information with our weather data from the same time frame. We conducted some simple EDA. As indicated in the figure below, there is seasonal variation, with more shootings occurring in summer months than in the winter.


```{r average # shootings bar plot, results='asis'}

#ERG
shoot_Month <- NYweathshoot_06 %>%
  group_by(month) %>%
  summarize("Shootings" = mean(Shootings, na.rm=T),
            "Shooting murders" = mean(Murders, na.rm=T))

# side-by-side bar plot
shoot_Month %>%
  dplyr::select(month, "Shootings", "Shooting murders") %>%
  gather(key="Value", value="Count", "Shootings", "Shooting murders") %>% 
  ggplot(aes(x=month, y=Count, fill=Value)) +
  geom_col(na.rm=TRUE, alpha=0.5, color="black", position="dodge") +
  labs(title="Average NYC Daily Shootings (2006-2021) by month", x="Month", y="Number of shootings") +
  scale_fill_manual(values=c("red", "blue"))

```

```{r}
#making scatter plot of Shootings v TMAX-- ERG Add
ggplot(NYweathshoot_06, aes(x = TMAX, y = Shootings, color = month)) +
    geom_point() +
    xlab(label = "TMAX (degrees Fahrenheit)") +
    ylab(label = "# Shootings") +
    ggtitle(label = "Number of NYC Shootings v. TMAX")

ggplot(NYweathshoot_06, aes(x = PRCP, y = Shootings, color = month)) +
    geom_point() +
    xlab(label = "PRCP (inches)") +
    ylab(label = "# Shootings") +
    ggtitle(label = "Number of NYC Shootings v. PRCP")

ggplot(NYweathshoot_06, aes(x = year, y = Shootings, color = month)) +
    geom_point() +
    xlab(label = "year") +
    ylab(label = "# Shootings") +
    ggtitle(label = "Number of NYC Shootings v. year")
```


We then completed a simple correlation plot, and observed negative correlations between number of shootings with `year` and `PRCP`, and a positive correlation with `SNOW` and `TMAX`.  

```{r}
# correlation between shooting & weather data
NYweathshoot_06_cor <- subset(NYweathshoot_06, select = c(year, day, TMAX, PRCP, SNOW, Shootings))
#str(NYweathshoot_06_cor)
shootcor <- cor(NYweathshoot_06_cor, use = "pairwise.complete.obs")
corrplot::corrplot(shootcor)
cor
```

We wanted to use all of these variables as regressors in a linear model. EDA revealed that the shooting data are not normally distributed, but are right-skewed -- not surprising, given that they are bound on the left side by zero -- as apparent in the plot below.  

```{r}
ggplot(NYweathshoot_06) +
  geom_histogram(aes(x=Shootings), na.rm=TRUE, alpha=0.5, color="black", bins=100, binwidth=2, fill = "green") + 
  labs(title="Distribution of daily NYC shootings (2006-2021)", x="Number of daily Shootings", y="Count")

#Not quite normal-- necessarily right-skewed, but a lot of data points...

```

However, since there were > 5,000 data points we created a linear model anyhow, using year and our main weather variables as regressors (we tried using month also, but most of the resulting coefficients for this factor variable were not statistically significant).  

```{r}
#modeling Shootings

NYweathshoot_06$month <- as.factor(NYweathshoot_06$month)

#shoot_lm <- lm(formula = Shootings ~ year + month + day + SNOW + PRCP + TMAX + TMIN, data = NYweathshoot_06) 
#shoot_lm <- lm(formula = Shootings ~ year + month + SNOW + PRCP + TMAX, data = NYweathshoot_06) # fit is better, but some parameters are not significant.

#this is the most reasonable model (EDA not included)
shoot_lm <- lm(formula = Shootings ~ year + SNOW + PRCP + TMAX, data = NYweathshoot_06) 
summary(shoot_lm) 

```

All fit parameters for this linear model (`Shootings ~ year + SNOW + PRCP + TMAX`) were significant (p-values of coefficients less than 0.05), and the multiple $R^2$ was 0.129. This suggests that the number of shootings per day in New York City between 2006 and 2021 has been decreasing; that statistically significantly fewer shootings are likely when it is raining; and that shootings are more likely to be reported when it is snowing than when it is not, and for higher daily maximum temperatures. 

These correlations could reflect trends in human predilection for gun violence as a function of weather (when it's raining, do people stay home instead of going out with their guns? when it's hotter, are they somewhat more likely to be riled up enough to fire them?). Or it could reflect different availability or ability of individuals to report shootings based on weather conditions (fewer witnesses when it's raining? improved ease of spotting blood in the snow?). It would be difficult to understand any underlying causality without studying these individuals using social science methods-- including interviews and further statistical analysis-- or by bringing in additional data that might account for number of people out on the street or where shootings are most likely to occur. 


```{r}
#TESTING ASSUMPTIONS
#Generate residual and predicted values
#NYweathshoot_06$resids0 <- residuals(shoot_lm)
#NYweathshoot_06$preds0 <- predict(shoot_lm)
#NYweathshoot_06$sq_preds0 <- (NYweathshoot_06$preds0)^2

#plot resids
#plot(resids0 ~ preds0, data = NYweathshoot_06,
#xlab = "Predicted Values",
#ylab = "Residuals")

```

However, the residuals for this model were not quite evenly balanced, so we  we experimented with variable transformation, to see if we could generate a more predictive model, taking:  
1. the square root of the daily number of shootings, and  
2. the log of (1 + the daily number of shootings),   
both of which generated a more normally distributed response variable.  

```{r}
#sqrt transformation of variable  
NYweathshoot_06$Shootvt <- (NYweathshoot_06$Shootings)^0.5

#log(x+1) transf of variable
NYweathshoot_06$Shootvt1 <- log(NYweathshoot_06$Shootings + 1)

#plot of sqrt transformed variable

ggplot(NYweathshoot_06) +
  geom_histogram(aes(x=Shootvt), na.rm=TRUE, alpha=0.5, color="black", bins=15, binwidth=1, fill = "green") + 
  labs(title="Distribution of Sqrt Number of Daily NYC Shootings (2006-2021)", x="Sqrt Number of Daily Shootings", y="Count")

#plot of log(x+1) transformed variable

ggplot(NYweathshoot_06) +
  geom_histogram(aes(x=Shootvt1), na.rm=TRUE, alpha=0.5, color="black", bins=15, binwidth=1, fill = "green") + 
  labs(title="Distribution of Log Number of Daily NYC Shootings (2006-2021)", x="Log(Number of Daily Shootings + 1)", y="Count")
```

```{r}
#edited

#model for sqrt transf
shootvt_lm <- lm(formula = Shootvt ~ year + SNOW + PRCP + TMAX, data = NYweathshoot_06) 
summary(shootvt_lm)
# This fit is better, with multiple r-squared of 0.138

#model for log transf
shootvt_lm1 <- lm(formula = Shootvt1 ~ year + SNOW + PRCP + TMAX, data = NYweathshoot_06) 
summary(shootvt_lm1)

```

These dependent variable-transformed models are of similar quality, both with an adjusted $R^2$ of 0.137, an improvement over the 0.128 value for the linear model with a non-transformed regressand (all models have F-statistic p-values of less than 0.05). Interestingly, in the variable-transformed models, the model coefficient for `SNOW` was not statistically significant in the new model. Given the relatively low $R^2$ values, we did not attempt to use these models for prediction.  

## Arrest data

After looking at the relationship between reported shootings in NYC and local weather, we looked at arrests in New York (for any crime). As with the shootings data, these data were not previously analyzed by our group so we did some basic EDA to determine the distribution of the new data and identify correlations that exist.

For this and the later analyses of weather's relationship with human activity, we used `TMAX`, the daily maximum temperature, and `precipitation factor`, a binary value for whether or not it rained or snowed on a daily basis. We incorporated `month` and `year` into these relationships as we saw seasonality effects and changes over time in our previous effort.

```{r}
# Add a column to convert PRCP to a binary factor variable. Don't care how much it rains, only if it rains. 
NYweath_prcpFact <-NYweath_final

NYweath_prcpFact$PRCP_factor <- cut(NYweath_final$TOT_PRCP, c(-Inf,0, Inf), labels = c(0,1))
NYweath_prcpFact$PRCP_factor <- as.factor(NYweath_prcpFact$PRCP_factor)

```

```{r}

#NYcrime <- data.frame(read.csv("/Users/christopherwasher/Documents/DATS6101/NYPD_Arrests_Data__Historic_.csv"))



#NYcrime_agg <- NYcrime %>% count(ARREST_DATE)

NYcrime_count <- tibble(read.csv("./data/NYPD_Arrests_counts.csv"))

NYcrime_count$ARREST_DATE <- as.Date(NYcrime_count$ARREST_DATE, format = "%Y-%m-%d")
#NYcrime_count$day <- format(NYcrime_count$ARREST_DATE, format="%d")
#NYcrime_count$month <- format(NYcrime_count$ARREST_DATE, format="%m")
#NYcrime_count$year <- format(NYcrime_count$ARREST_DATE, format="%Y")

colnames(NYcrime_count)[2] <- "ARREST_DATE"

#head(NYcrime_count)
#summary(NYcrime_count)

```


```{r}

#crime_plot <- plot(NYcrime_count$ARREST_DATE, NYcrime_count$NUM_ARREST)
#crime_boxplot <- boxplot(NYcrime_count$NUM_ARREST)
crime_hist <- ggplot(NYcrime_count, aes(x = NYcrime_count$NUM_ARREST)) + 
  geom_histogram(fill = "cornflowerblue") + 
  labs(x = "Number Daily Arrests",
       title = "Distribution of Daily NYC Arrest Counts")
crime_hist

```

The histogram shows the distribution of the number of daily `arrests` in NYC to be a slight bimodal distribution. However, because of the large sample size, we will consider this a normal distribution.  

We plotted `arrests` and `TMAX`, with points coded by `precipitation factor` and `month`. This plot is below with no initial patterns that can be discerned.  

```{r, results='markup'}


crimeWeather <- subset(NYweath_prcpFact, year >= 2006 & year < 2022)
NYcrime_count <- NYcrime_count[order(NYcrime_count$ARREST_DATE),]

#tail(crimeWeather)
NYweath_crime <- cbind(crimeWeather, NYcrime_count$NUM_ARREST)
colnames(NYweath_crime)[12] <- c("NUM_ARREST")

#NYweath_crime_plot <- plot(sqrt(NYweath_crime$PRCP), NYweath_crime$NUM_ARREST)
#boxplot((NYweath_crime$TOT_PRCP))

#NY_weathcrime_ggplot <- ggplot(NYweath_crime,
 #                              aes(x = TMAX, y =NUM_ARREST)) + 
  #geom_point(aes(colour = PRCP_factor), alpha = 0.5) +
  #labs(x = "Temperature (ºF)", y = "Number of Daily Arrests", 
  #     title = "Weather Patterns for NYC Crime")
#NY_weathcrime_ggplot

NY_weathcrime_ggplot2 <- NYweath_crime %>% 
  sample_frac(0.25) %>%
  ggplot(aes(x = TMAX, y =NUM_ARREST)) + 
  geom_point(aes(shape = PRCP_factor, colour = month)) +
  labs(x = "Temperature (ºF)", y = "Number of Daily Arrests", 
       title = "Weather Patterns for NYC Crime") + 
  guides(colour = guide_legend(nrow = 6))
NY_weathcrime_ggplot2

```



```{r}

crime_prcp1 <- subset(NYweath_crime, PRCP_factor == 1)
crime_prcp0 <- subset(NYweath_crime, PRCP_factor == 0)

crime_count_ttest <- t.test(crime_prcp0$NUM_ARREST, crime_prcp1$NUM_ARREST)
crime_count_ttest


```

We performed a t-test and determined a significantly higher number of arrests on days without precipitation.  

We also looked at the a correlation plot for weather variables and `arrests`. The strongest correlation exists between number of `arrests` and `year`, followed by `month`. Temperature appears to have no correlation with crime while precipitation has a very minimal negative correlation with crime. However, we know these correlations might not tell the whole story so we created a linear regression model that incorporates all of these variables.  

```{r, results = 'markup'}
crime_cor_data <- NYweath_crime
crime_cor_data$NUM_ARREST <- as.numeric(crime_cor_data$NUM_ARREST)
crime_cor_data <- cbind(crime_cor_data[3:6], crime_cor_data[8:12])

pairs.panels(crime_cor_data, 
             method = "pearson", # correlation method
             hist.col = "#00AFBB",
             density = FALSE,  # show density plots
             ellipses = FALSE, # show correlation ellipses
             )

```


```{r, results ='markup'}

#crimeWeath_lm <- lm(NUM_ARREST ~ TMAX + PRCP_factor + year,  
                 #   data = NYweath_crime)
crimeWeathMonth_lm <- lm(NUM_ARREST ~ TMAX + PRCP_factor + year + month, 
                    data = NYweath_crime)
#crimeWeathTMIN_lm <- lm(NUM_ARREST ~ (TMIN + PRCP_factor), 
#                    data = NYweath_crime)

#summary(crimeWeathMonth_lm)
xkabledply(crimeWeathMonth_lm, title = paste("Linear Model: ",                                           format(formula(crimeWeathMonth_lm) )))

```

The linear model of arrests as predicted by of `TMAX`, `precipitation factor`, `year`, and `month` regressors. The model has an overall R^2 value 0.427 which is a weak overall fit for the data, but does indicate that these regressors explain some of the variability in the data. The coefficients for `TMAX`, `precipitation factor`, `year`, and most `months` are statistically significant.  

There is a weak positive relationship between `arrests` and `TMAX`, for every degree increase in temperature there are about 2.34 more arrests.  `Precipitation factor` had a slightly more impactful effect on the number of daily arrests. The linear model shows a decrease of 46.13 arrests on days with precipitation, confirming what we saw in our t-test. The model also shows a decreasing number of arrests over time and that most months have a statistically significant relationship with the number of daily arrests.  


##Stock Market  


Next, we looked at the effect weather has on the stock market, looking at the trade volume of the Dow Jones Industrial index in the 1990s. This time period was chosen due to the transition to digital stock trading with the rise of computers. We hypothesized that if weather had an effect on trade volume, the effect would be greatest for this time given the data available.

To start investigating this relationship, initial EDA was performed.  

``` {r}

NYstock <- tibble(read.csv("./data/Dow Jones Industrial Average Historical Data.csv"))

tail(NYstock)

NYstock$Date <- as.Date(NYstock$Date, format = "%m/%d/%y")

NYstock2 <- NYstock
NYstock2 <- NYstock2 %>% 
  complete(Date = seq.Date(min(Date), max(Date), by="day"))

options(scientific=T, digits = 10)

# This is all just test code for figuring out how to clean the data. 
# Not part of final script.
#NYstocktest <- NYstock2
#NYstocktest$Vol. = substr(NYstocktest$Vol.,1,nchar(NYstocktest$Vol.)-1)
#tail(NYstocktest)


#NYstocktest$Price <- gsub(",", "", NYstocktest$Price)
#NYstocktest[3:5] <- lapply(NYstocktest[3:5], gsub, pattern = ",", replacement = "") 
#NYstocktest$Change.. <- gsub("%", "", NYstocktest$Change..)
#NYstocktest[2:7] <- sapply(NYstocktest[2:7], as.numeric)
###

NYstock2$Vol. = substr(NYstock2$Vol., 1, nchar(NYstock2$Vol.) - 1)
NYstock2[2:5] <- lapply(NYstock2[2:5], gsub, pattern = ",", replacement = "") 
NYstock2$Change.. <- gsub("%", "", NYstock2$Change..)
NYstock2[2:7] <- sapply(NYstock2[2:7], as.numeric)

NYstock2$day <- format(NYstock2$Date, format="%d")
NYstock2$month <- format(NYstock2$Date, format="%m")
NYstock2$year <- format(NYstock2$Date, format="%Y")



head(NYstock2)
summary(NYstock2)
options(scientific=T, digits = 3) 

```


```{r}

NYstock_final <- NYstock2[,c("Date", "Vol.")]
NYstock_final <- subset(NYstock_final, Date <= "2022-09-26")
weather_stockDates <- subset(NYweath_prcpFact, DATE >= "1979-12-25")

stockWeather <- cbind(weather_stockDates, NYstock_final)
colnames(stockWeather)[13] <- c("Stock_Volume")

```


```{r, results='markup'}
stockWeather_rmNA <- subset(stockWeather, !is.na(Stock_Volume))
stock_hist <- hist(stockWeather_rmNA$Stock_Volume)
stockWeather_rmNA_gghist <- ggplot(stockWeather_rmNA, 
                                aes(x = stockWeather_rmNA$Stock_Volume)) + 
  geom_histogram(fill = "cornflowerblue") + 
  labs(x = "Total Daily Trade Volume (M) ",
       title = "Distribution of Daily DOW Trade Volume")
stockWeather_rmNA_gghist

```

The histogram of the daily DOW `stock volume` shows the data is right skewed so we used a square root normalization of the volume, and reexamined the distribution.

```{r, results='markup'}

stockWeather_rmNA$StockVolume_norm <- sqrt(stockWeather_rmNA$Stock_Volume)
stockWeather_rmNA <- subset(stockWeather_rmNA, select = -c(Date))
stockWeather_90s <- subset(stockWeather_rmNA, year >= 1988 & year <= 1999)

#hist(stockWeather_90s$Volume_norm)
#boxplot(stockWeather_rmNA$Volume_norm)
stockWeather90Norm_rmNA_gghist <- ggplot(stockWeather_90s, 
                            aes(x = stockWeather_90s$StockVolume_norm)) +
  geom_histogram(fill = "cornflowerblue") + 
  labs(x = "Normalized Daily Trade Volume (M) ",
       title = "Distribution of Normalized DOW Trade Volume")
stockWeather90Norm_rmNA_gghist

```

The distribution of normalized Volume is considerably more normal, although there still appears to be a right-skew to the distribution. Given the number of observations, we will assume this is a normal enough distribution for further analysis.


```{r}

stock_prcp1 <- subset(stockWeather_90s, PRCP_factor == 1)
stock_prcp0 <- subset(stockWeather_90s, PRCP_factor == 0)

stock_count_ttest <- t.test(stock_prcp0$StockVolume_norm,
                            stock_prcp1$StockVolume_norm)
stock_count_ttest


```

A t-test was performed to compare the mean normalized `stock volume` on days with and without precipitation. The t-test did not reject the null hypothesis as the values are nearly identical regardless of precipitation. We then wanted to look at correlations between all the variables.


```{r, results='markup'}

pairs.panels(stockWeather_90s[c("year", "month", "TMAX",
                                "TOT_PRCP","PRCP_factor",
                                 "Stock_Volume","StockVolume_norm")], 
             method = "pearson", # correlation method
             hist.col = "#00AFBB",
             density = FALSE,  # show density plots
             ellipses = FALSE # show correlation ellipses
             )

```

The only strong correlation that exists in this data set is the relationship between year and the `stock volume`. There are no other strong correlations present in the data. This is apparently supported by the scatter plot of `Stock Volume vs TMAX`, with points encoded by `month` and `PRCP factor`.

```{r}


#NY_weathstock_scatter <- ggplot(stockWeather_rmNA, aes(x = TMAX, y #=Volume_norm)) + 
#  geom_point(aes(colour = PRCP_factor)) +
#  labs(x = "Temperature", y = "Total Daily DOW Trade Volume", 
 #      title = "Weather Patterns for DOW Trade Volume")
#NY_weathstock_scatter


## Trying again with the 90's stock data.

#NY_90s_weathstock_scatter <- ggplot(stockWeather_90s, aes(x = TMAX, y =Volume_norm)) + 
#  geom_point(aes(colour = PRCP_factor)) +
#labs(x = "Temperature (ºF)", y = "Normalized Daily DOW Trade Volume (M)", 
 #      title = "Weather Patterns for DOW Trade Volume in the 1990s")
#NY_90s_weathstock_scatter

NY_90s_weathstock_scatter2 <- stockWeather_90s %>% 
  sample_frac(0.3) %>%
  ggplot(aes(x = TMAX, y =StockVolume_norm)) + 
  geom_point(aes(colour = month, shape = PRCP_factor)) +
  labs(x = "Temperature (ºF)", y = "Normalized Daily DOW Trade Volume (M)",
       title = "Weather Patterns for DOW Trade Volume in the 1990s") + 
  guides(colour = guide_legend(nrow = 6))
NY_90s_weathstock_scatter2

```

A linear model was created to highlight potential hidden relationships that may exist in the data.  

```{r, results='markup'}


#stock_LM <- lm(Volume_norm ~ TMAX + PRCP_factor + year + month,
 #              stockWeather_rmNA)
#summary(stock_LM)


stock_LM_90s <- lm(StockVolume_norm ~ TMAX + PRCP_factor + year + month,
                   stockWeather_90s)
#summary(stock_LM_90s)
xkabledply(stock_LM_90s, title = paste("Linear Model: ",                                           format(formula(stock_LM_90s) )))


```

The linear model incorporates all the `stock volume` data from 1988-2000 had a statistically significant `TMAX`, `year`, and some of the `month`s. The relationship between `TMAX` and `stock volume` is misleading because of the difference in scale between the variables. The `stock volume` is on the scale of millions so even though there is a statistically significant relationship, it is not a strong correlation. The relationship with `TMAX` is more likely related to the seasonality that is shown by the statistically significant months in the model as the warmer months more statistically significant. The overall model has an r-squared value of 0.641, but that is likely primarily driven by the year variable, as indicated by the strong correlation above.


### COVID Data

The last human activity we wanted to explore was public health by looking at a relationship between weather and COVID-19 `case counts`. In our previous effort, we saw that COVID-19 lockdown had an effect on the temperature in NYC so here we are looking for weather's effect on the number of cases in the city. 

One notable flaw with this use of the dataset was that its `case counts` were tracked based on confirmation dates rather than test dates, which means the weather data does not always match up to the case number dates. We continued with the analysis with the assumption that same day tests would out number longer turnaround tests and relationships that exist would still be identifiable. 

This was new data for our team so we performed initial EDA followed by a linear model to observe relationship with weather and COVID-19 `case counts`.  

``` {r}
options(scientific=T, digits = 3) 
NYcovid <- tibble(read.csv("./data/COVID-19_Daily_Counts_of_Cases__Hospitalizations__and_Deaths.csv"))

NYcovid <- select(NYcovid, 1:3)

head(NYcovid)
colnames(NYcovid)[1] <- "DATE"

NYcovid$DATE <- as.Date(NYcovid$DATE, format = "%m/%d/%Y")
NYcovid$day <- format(NYcovid$DATE, format="%d")
NYcovid$month <- format(NYcovid$DATE, format="%m")
NYcovid$year <- format(NYcovid$DATE, format="%Y")

head(NYcovid)
summary(NYcovid)

#hist(NYcovid$CASE_COUNT)

```

```{r, results='hide'}

#covid_plot <- plot(NYcovid$DATE, NYcovid$CASE_COUNT)
#covid_boxplot <- boxplot(NYcovid$CASE_COUNT)

NYcovid_rmOuts <- outlierKD2(NYcovid, CASE_COUNT, rm=TRUE, boxplt=F, histogram=F, qqplt=F)

NYcovid_rmOuts2 <- outlierKD2(NYcovid_rmOuts, CASE_COUNT, rm=TRUE, boxplt=F, histogram=F, qqplt=F)

NYcovid_rmOuts3 <- outlierKD2(NYcovid_rmOuts2, CASE_COUNT, rm=TRUE, boxplt=F, histogram=F, qqplt=F)

NYcovid_rmOuts4 <- outlierKD2(NYcovid_rmOuts3, CASE_COUNT, rm=TRUE, boxplt=F, histogram=F, qqplt=F)


#covid_plot <- plot(NYcovid_rmOuts4$DATE, NYcovid_rmOuts4$CASE_COUNT)
tail(NYcovid_rmOuts3)


sqrt_count <- sqrt(NYcovid_rmOuts3$CASE_COUNT)
#hist(sqrt_count)

NYcovid_final <- cbind(NYcovid_rmOuts4, sqrt_count)
head(NYcovid_final)

```

```{r, results='markup'}


cov_final_hist <- ggplot(NYcovid_final, 
                            aes(x = NYcovid_final$sqrt_count)) +
  geom_histogram(fill = "cornflowerblue", ) + 
  labs(x = "Normalized COVID Case Count ", y = "Frequency",
       title = "Distribution of Normalized COVID Case Count")
cov_final_hist


```

The COVID `case count` data was extremely skewed right so outliers were removed and a square-root transform was used to normalize the data.  


```{r}

covWeather <- subset(NYweath_prcpFact, DATE >= ("2020-02-29"))
NYcovid_finaldates <- subset(NYcovid_final, DATE <= "2022-09-26")
tail(covWeather)
NYweath_prcpCov <- cbind(covWeather, NYcovid_finaldates$CASE_COUNT,
                         NYcovid_finaldates$sqrt_count)
colnames(NYweath_prcpCov)[12:13] <- c("CASE_COUNT", "sqrt_count")

covCount_prcp_plot <- plot(NYweath_prcpCov$sqrt_count, sqrt(NYweath_prcpCov$PRCP))

NYweath_cov_final <- NYweath_prcpCov[,c(1:5, 8, 10:13)]

```

A t-test comparing COVID-19 `case counts` on days with precipitation and days without precipitation was then performed. There was not a statistically significant difference in the mean number of COVID-19 `case counts` on days with and without precipitation. Boxplots of the precipitation and no precipitation COVID `case counts` are below.  

```{r}

cov_prcp1 <- subset(NYweath_cov_final, PRCP_factor == 1)
cov_prcp0 <- subset(NYweath_cov_final, PRCP_factor == 0)

cov_count_ttest <- t.test(cov_prcp0$sqrt_count, cov_prcp1$sqrt_count)
cov_count_ttest
```

```{r, results = 'markup'}
cov_count_bplot <- ggplot()+
  geom_boxplot(data = NYweath_cov_final,
               aes(y = sqrt_count, x = PRCP_factor, fill = PRCP_factor)) +
  labs(title = "COVID Positive Counts")

cov_count_bplot
```

```{r}


## Repeating this EDA looking only at Covid cases from 2021+. 
cov_2021 <- subset(NYweath_cov_final, year >= 2021)

cov_2021count_bplot <- ggplot()+
  geom_boxplot(data = cov_2021, aes(y = sqrt_count, x = PRCP_factor)) +
  labs(title = "2021 COVID Positive Counts")
cov_2021count_bplot

cov_2021prcp1 <- subset(cov_2021, PRCP_factor == 1)
cov_2021prcp0 <- subset(cov_2021, PRCP_factor == 0)

cov_2021count_ttest <- t.test(cov_2021prcp0$sqrt_count, cov_2021prcp1$sqrt_count)
cov_2021count_ttest

```

Following the t-test, we wanted to look at the correlations of all the variables that can be included in a linear model.  

```{r}
library(psych)


pairs.panels(NYweath_cov_final[4:10], 
             method = "pearson", # correlation method
             hist.col = "#00AFBB",
             density = FALSE,  # show density plots
             ellipses = FALSE # show correlation ellipses
             )
```

The strongest correlation existed between `year` and the COVID-19 `case counts`, followed by a negative correlation between daily temperature and `case counts`. There was no correlation between precipitation and COVID `case counts`. 

These variables were plotted in the scatter plot below to visualize the relationships prior to building the linear model.


```{r}

covWeath_final_scatter <- ggplot(NYweath_cov_final, 
                                 aes(x = TMAX, 
                                     y =sqrt_count,
                                     )) + 
  geom_point(aes(colour = month, shape = PRCP_factor)) +
  labs(x = "Temperature", 
       y = "Normalized COVID-19 Case Counts", 
       title = "Weather Patterns for Covid Case Counts") + 
  guides(colour = guide_legend(nrow = 6))

covWeath_final_scatter

```

We built a linear model that predicts the normalized COVID-19 `case counts` using `TMAX`, `precipitation factor`, `year`, and `month`, as the regressors.


```{r, results='markup'}

#cov_weathLM <- lm(sqrt_count ~ TMAX + PRCP_factor + year,
 #                 data = NYweath_cov_final)
#summary(cov_weathLM)

cov_weathLM_month <- lm(sqrt_count ~ TMAX + PRCP_factor + year + month,
                  data = NYweath_cov_final)
#summary(cov_weathLM_month)
xkabledply(cov_weathLM_month, title = paste("Linear Model: ",                                           format(formula(cov_weathLM_month) )))



#cov2021_weathLM <- lm(CASE_COUNT ~ TMAX + PRCP_factor + year + month,
 #                 data = cov_2021)
#summary(cov2021_weathLM)

```

The linear model predicting COVID-19 cases in New York City with weather, year, and month as regressors. The model has an Adjusted R-squared value of 0.347. This indicates the model is a weak fit but it does explain some of the variation in the number of cases. The model coefficients are not all significant. Both `TMAX` and `precipitation factor` are not statistically significant in this model. Instead, `year` and most `months` are statistically significant, which drives the fit and predictive ability of the model.

## Linear Regression to Predict Precipitation!

The last analysis performed does not directly address our original questions, but our team looked to use the relationships between human activity and weather to predict `precipitation factor`.  

Our team built a logistic regression to predict `precipitation factor` using `TMAX`, `year`, `month`, and human activity via number of `arrests` and `stock volume.` These two variables were chosen for human activity because the previous linear models show they had some statistical significant relationship to weather.  


```{r}

stock_masterDates <- subset(NYstock_final,Date >= "2006-01-01" &
                              Date <= "2021-12-31")

crime_masterDates <- NYcrime_count

weath_masterDates <- subset(NYweath_prcpFact, year >= 2006 & year < 2022) 


master_log <- cbind(weath_masterDates,
                    crime_masterDates$NUM_ARREST,
                    stock_masterDates$Vol.)
colnames(master_log)[12:13] <- c('NUM_ARREST', 'Stock_Volume')

head(master_log)


```

```{r}

master_logFinal <- subset(master_log, !is.na(Stock_Volume))
master_logFinal$StockVolume_norm <- sqrt(master_logFinal$Stock_Volume)

```

```{r, results='markup'}

prcp_logit <- glm(PRCP_factor ~ TMAX + NUM_ARREST +
                    StockVolume_norm + year + month,
                  data = master_logFinal,
                  family = binomial(link = "logit"))

#summary(prcp_logit)
xkabledply(prcp_logit, title = paste("Logistic Model: ",                                           format(formula(prcp_logit) )))

```

The logit model to predict the log odds of precipitation factor, most of the coefficients in the model are not statistically significant. `Year`, two separate `months`, and number of `arrests` are statistically significant. For `year`, for every one unit increase in year, the odds of precipitation decrease by a factor of 0.01. This is not a particularly strong effect on the odds. For number of `arrests`, for every additional arrest, the odds of precipitation decrease by a factor 0.001. This again is not a strong effect, but when accounting for the difference in scale for number of arrests per day, this is a more interesting relationship.  


```{r}
library(ModelMetrics)
prcpLR_cm <- confusionMatrix(actual = prcp_logit$y, 
                  predicted = prcp_logit$fitted.values)
prcpLR_cm

prcpLR_acc <- (prcpLR_cm[2,2] + prcpLR_cm[1,1])/(sum(prcpLR_cm))
prcpLR_prec <- (prcpLR_cm[2,2])/(prcpLR_cm[2,2]+prcpLR_cm[1,2])
prcpLR_rec <- (prcpLR_cm[2,2])/(prcpLR_cm[2,2]+prcpLR_cm[2,1])
prcpLR_spec <- (prcpLR_cm[1,1])/(prcpLR_cm[1,1]+prcpLR_cm[1,2])


library(pscl)
prcp_pr2 <- pR2(prcp_logit)
prcp_pr2

```

Unfortunately, this logistic regression is not a great model to predict precipitation. The overall accuracy of the model, using a default cutoff of 0.5, is 0.64. This is not a great improvement over a null model. Additionally, the precision for this model is only 0.03 and the recall rate is only 0.51.  

The McFadden value for this model is 0.01, which shows this model does not explain any variability in the precipitation.   

We also plotted the receiver operator characteristic (ROC) to measure the true positive rate verse the true negative rate of this model.  


```{r, results='markup'}
library(pROC)

master_logFinal$prob=predict(prcp_logit, type = c("response"))
prcp_roc <- roc(PRCP_factor ~ prob, data = master_logFinal)
prcp_auc <- pROC::auc(prcp_roc)
prcp_auc
plot(prcp_roc)

```


The area under the ROC curve is 0.575. This confirms the model is not a good fit as it is only slightly greater than the null AUC of 0.5.

However, this logistic regression appears to confirm a relationship between number of `arrests` and `precipitation.` This relationship would be something of interest to explore further in future study.  

# Conclusions

Overall,we have identified statistically significant correlations between weather, air quality, and human activity data from NYC-- but none of our models demonstrate high predictive potential.

We were unable to develop a model for Central Park warming on a century scale, due to a lack of quality data over this time frame that accounted for relevant human activities (such as expansion of the built environment, local population or greenhouse gas emissions on a daily basis). This work has given us a new appreciation of just how complicated weather and climate models must be-- especially if they are to be used predictively.

In our air quality analysis, our hypothesis that a correlation would exist between daily weather and air quality variables was ultimately proven wrong. We observed trends of declining AQI over time, but the explanation of variance from our model results was not strong enough to deem the model a good fit. Similarly, a linear model predicting AQI based on the categorical month variable, along with TMAX, also resulted in a poor fit.  

We determined that the relationship between air quality and global warming is difficult to model using linear techniques due to seasonal trends in the variables. Our attempt to model the effect of these trends using kNN also resulted in a poor-fitted model. Ultimately, a different type of model would be required to address the seasonal component.  

Also, changes in climate are slow to take effect. A increase in emissions does not necessarily lead to increases in temperature on the same time scale. All these effects would need to be taken into consideration for an effective analysis.

We did identify correlations between daily weather and local human activity in some areas. Both crime and stock market trade volume had statistically significant correlations to daily weather variables in our linear models. Crime (daily numbers of shootings and arrests) is correlated to both temperature and precipitation while stock market trade volume is related to temperature. However, models based on these correlations are not strong or complete enough to be predictive.

Observed correlations between crime and weather were the strongest we found in this analysis. This represents a valuable area for future study in the context of changing weather patterns that was explored in our early project.

There were notable limitations to the methods in this analysis. One key limitation that affected the analysis of public health was the availability of essential data. The COVID-19 case data was based on dates when positive cases were confirmed, rather than tested. Because test and confirmation dates are not always the same, this limited our ability assess relationships that existed on the day of an individual's test. Looking for alternative data sources to explore this relationship would be an interesting area for a future project. From our results, we also conclude that linear models might not be optimal for representing data with seasonal trends.  

These questions are only some of the important questions that should be asked about the relationship between humans, weather, climate, and the environment. As climate change continues, it will be increasingly important to continue to study its effects on people, from the global scale down to local communities around the world. 


# References

City of New York. _NYPD Shooting Incident Data (Historic)_ retrieved December 6, 2022, from https://data.cityofnewyork.us/Public-Safety/NYPD-Shooting-Incident-Data-Historic-/833y-fsy8  

Lindsey, R.; Dahlman, L. (2022, June 28). _Climate change: Global temperature._ Climate.gov. Retrieved December 11, 2022, from https://www.climate.gov/news-features/understanding-climate/climate-change-global-temperature  

NYC Environment and Health Data Portal, _Tracking changes in New York City's sources of air pollution._, published online April 12, 2021, retrieved December 6, 2022, from https://a816-dohbesp.nyc.gov/IndicatorPublic/beta/data-stories/aq-cooking/  

NOAA National Centers for Environmental Information, _Monthly Global Climate Report for Annual 2021_, published online January 2022, retrieved on November 2, 2022 from https://www.ncei.noaa.gov/access/monitoring/monthly-report/global/202113  

NOAA National Centers for Environmental Information, "Climate Data Online." Custom data requests and downloads retrieved on October 1 (Central Park data) and October 16, 2022 (JFK data) from https://www.ncdc.noaa.gov/cdo-web/  

Parida, B. R., Bar, S., Kaskaoutis, D., Pandey, A. C., Polade, S. D., & Goswami, S. (2021). _Impact of COVID-19 induced lockdown on land surface temperature, aerosol, and urban heat in Europe and North America._ Sustainable cities and society, 75, 103336. https://doi.org/10.1016/j.scs.2021.103336  

Storms, C. (2015). _New York City Panel on Climate Change 2015 Report: Executive summary._ Ann NY Acad Sci, 1336, 9-17. Retrieved on October 29, 2022 from https://nyaspubs.onlinelibrary.wiley.com/doi/10.1111/nyas.14008  

United States Environmental Protection Agency (EPA), _Air Data Basic Information._, retrieved December 8, 2022, from, https://www.epa.gov/outdoor-air-quality-data/air-data-basic-information  

United States Environmental Protection Agency (EPAa), _Climate Change Indicators: U.S. and Global Precipitation_, published online August 2022, retrieved on November 2, 2022 from https://www.epa.gov/climate-indicators/climate-change-indicators-us-and-global-precipitation  

United States Environmental Protection Agency (EPAb), _Learn About Heat Islands._ Retrieved on November 3, 2022 from https://www.epa.gov/heatislands/learn-about-heat-islands 

Horanont, T., Phithakkitnukoon, S., Leong, T. W., Sekimoto, Y., & Shibasaki, R. (2013). _Weather effects on the patterns of people's everyday activities: a study using GPS traces of mobile phone users._ PloS one, 8(12), e81153. https://doi.org/10.1371/journal.pone.0081153

https://www.climate.gov/news-features/understanding-climate/climate-change-global-temperature


