---
title: "Project 2 EDA"
author: "Tejas Rawal"
date: "`r Sys.Date()`"
output:
  html_document:
    code_folding: hide
    number_sections: false
    toc: yes
    toc_depth: 3
    toc_float: yes
  pdf_document:
    toc: yes
    toc_depth: '3'
---

```{r include=FALSE}
# The package "ezids" (EZ Intro to Data Science) includes a lot of the helper functions we developed for the course. 
# Some of the frequently used functions are loadPkg(), xkabledply(), xkablesummary(), uzscale(), etc.
library(ezids)
 
# some of common options (and the defaults) are: 
# include=T, eval=T, echo=T, results='hide'/'asis'/'markup',..., collapse=F, warning=T, message=T, error=T, cache=T, fig.width=6, fig.height=4, fig.dim=c(6,4) #inches, fig.align='left'/'center','right', 
# knitr::opts_chunk$set(warning = F, results = "markup", message = F)
knitr::opts_chunk$set(warning = F, results = "markup", message = F)
options(scientific=T, digits = 3) 
# options(scipen=9, digits = 3) 
# ‘scipen’: integer. A penalty to be applied when deciding to print numeric values in fixed or exponential notation.  Positive values bias towards fixed and negative towards scientific notation: fixed notation will be preferred unless it is more than ‘scipen’ digits wider.
# use scipen=999 to prevent scientific notation at all times
```

```{r data init}
#loading packages 
library(ezids)
#library(ggplot2)
library(ggrepel)
library(gridExtra)
#library(tibble)
library(tidyverse)
library(corrplot)

#loading data 
NYweath <- data.frame(read.csv("data/NYC_weather_1869_2022.csv"))

#converting to R date format and adding columns for day, month, and year
NYweath$DATE <- as.Date(NYweath$DATE)
NYweath$day <- format(NYweath$DATE, format="%d")
NYweath$month <- format(NYweath$DATE, format="%m")
NYweath$year <- format(NYweath$DATE, format="%Y")

#converting temperature observations to numerical
NYweath$TMAX <- as.numeric(NYweath$TMAX)
NYweath$TMIN <- as.numeric(NYweath$TMIN)
NYweath$TAVG <- as.numeric(NYweath$TAVG)
NYweath$year <- as.numeric(NYweath$year)

#Making month a factor
NYweath$month <- as.factor(NYweath$month)

# subset data to desired variables
NYweath_sub <- subset(NYweath, select = c(DATE, day, month, year, TMAX, TMIN, TAVG, PRCP, SNOW)) 

#creating a subset for 1900 on
NYweath_00 <- subset(NYweath_sub, year > 1899)
xkabledplyhead(NYweath_00)
```

## Analysis Questions

1. Logistic regression to predict rainy day based on TMAX, TMIN, MONTH, DAY?  
2. Linear correlations between Air Quality and Weather variables  
3. Can we predict the month based on weather variables (kNN)?  

### Logitic Model Preparation

First, we format our data to create a variable representing whether it rained on a given day, starting :

```{r rainy days data}
# add column based on condition of rain on a given day
NYweath.rain <- NYweath_00
NYweath.rain$rained <- ifelse(NYweath.rain$PRCP > 0.0, 1, 0)
NYweath.rain$rained <- as.factor(NYweath.rain$rained)
xkablesummary(NYweath.rain)
xkabledplyhead(NYweath.rain)
```

First, let's create a two-way contingency table To study the effects on rainy day by the factor month and make sure there are no cells of zero frequencies.  

```{r crosstable}
rainy_vs_month = xtabs(~ rained + month, data = NYweath.rain)
rainy_vs_month
```

We can then quickly run a chi-squared test to see if the two are independent (or same frequency distribution).  
```{r chisq}
chisq.result = chisq.test(rainy_vs_month)
chisq.result
```

Based on the result, the factor variables `rained` and `month` are dependent - there is a statistically significant relationship between the two. We can use the `month` variable in our logistic regression to predict the `rained` outcome for a day. 

### The Logistic Model

Let's jump to the logistic regression to predict a precipitation event on a given day:

```{r logit attempt}
rainedLogit <- glm(rained ~ month + TMAX + TMIN, data = NYweath.rain, family = "binomial")
summary(rainedLogit)
xkabledply(rainedLogit, title = paste("Logistic Regression :", format(formula(rainedLogit)) ))
```

All the coefficients are found significant (small p-values) except for the months of February, March, and April. TMAX has a negative effect on precipitation while TMIN has a positive effect. The months with significant coefficients all have a negative effect on the rain outcome for a given day.

Let's obtain the growth/decay factors for each explanatory variables. The factors are the exponentials of the coefficients:   

```{r growthDecayFactors, results='markup', collapse=F}
expcoeff = exp(coef(rainedLogit))
xkabledply(as.table(expcoeff), title = "Exponential of coefficients in rained Logit Reg")
```

Compared to January, the months of February and March have a positive effect on the probability of a rainy day. Each gain in the minimum daily temperature value also has a positive effect on chances of rain.  

### Logistic Model Evaluation

#### Confusion matrix
```{r logit confusion matrix}
library(ModelMetrics)
library(scales)

rainedLogit.confusion <- ModelMetrics::confusionMatrix(
  actual = rainedLogit$y,
  predicted = rainedLogit$fitted.values)

xkabledply(rainedLogit.confusion,
  title = "Confusion matrix for logit model")

accuracy <- (rainedLogit.confusion[4] + rainedLogit.confusion[1]) / nrow(NYweath.rain)
precision <- rainedLogit.confusion[4] / (rainedLogit.confusion[4] + rainedLogit.confusion[3])
```

The confusion matrix above was generated for the cutoff value of `0.5`.  

The accuracy of this logistic model is approx. `r format(accuracy, format = "f", digits = 2)` which shows that out of all predictions made by our model on whether it rained or not, `r format(100 * accuracy, format= "f", digits = 2)`% were correct.  

The precision value signals that it actually only rained on `r format(100 * precision, format= "f", digits = 2)`% of the days out of all days the model predicted it would rain.    

#### Mcfadden's Test
```{r logit mcfadden test}
rainedNullLogit <- glm(rained ~ 1, data = NYweath.rain, family = "binomial")
mcFadden = 1 - logLik(rainedLogit)/logLik(rainedNullLogit)
mcFadden
```

The McFadden test outputs a pseudo-R-square value of `r mcFadden[1]` which demonstrates that only about `r format(100 * mcFadden[1], format= "f", digits = 2)`% of the variation in rainy day outcomes is explained by our regressors. This is not a significant outcome for the likelihood that the model is correct at predicting rainy days.  

#### Hosmer and Lemeshow test  

The Hosmer and Lemeshow Goodness of Fit test can be used to evaluate logistic regression fit. 

```{r HosmerLemeshow}
library(ResourceSelection)
# Hosmer and Lemeshow test, a chi-squared test
rainedLogitHoslem = hoslem.test(NYweath.rain$rained, fitted(rainedLogit))
rainedLogitHoslem
```

The p-value of `r admitLogitHoslem$p.value` is very low which indicates that the model is a good fit.

#### ROC/AUC
```{r titanic logic roc/auc}
library(pROC)
probabilities <- predict(rainedLogit, type = "response")
# add probabilities as column
NYweath.rain$probs <- probabilities

rainedLogitROC <- roc(rained~probs, data=NYweath.rain)
plot(rainedLogitROC)
```

The area-under-curve of the ROC plot is `r format(rainedLogitROC$auc[1], digits = 2)`, which is less than the significance value of 0.8. The true positive rate of our model measure is about `r format(rainedLogitROC$auc[1] * 100, digits = 2)`%.  

Overall, I think we should attempt to find a different combination of predictors for this model.  

## NYC daily air quality data analysis

Let's pull in our air quality data. It contains measurements of daily PM2.5 and air quality index values taken from various locations around Manhattan.  

PM2.5 includes particles less than or equal to 2.5 micrometers and is also called fine particle pollution. The AQI is an index for reporting daily air quality. It tells how clean or polluted the air is, and what associated health effects might be a concern, especially for ground-level ozone and particle pollution.


Let's load the new data and have a look at it's structure:
```{r load csvs}
DailyAQ_00_22 <- data.frame(read.csv("data/daily-AQ-NY-00-20.csv"))
DailyAQ_00_22 <- DailyAQ_00_22[c('Date', 'Daily.Mean.PM2.5.Concentration', 'DAILY_AQI_VALUE')]
colnames(DailyAQ_00_22) <- c('DATE', 'PM2.5', 'AQI')
str(DailyAQ_00_22)
xkablesummary(DailyAQ_00_22)
xkabledplyhead(DailyAQ_00_22)
```

We need to convert the date from a character string to an R type. We also calculate year-over-year growth rates for both daily PM2.5 and AQI and store them in a column.

```{r formatting, echo = F}
DailyAQ_00_22$DATE <- as.Date(DailyAQ_00_22$DATE, "%m/%d/%y")

DailyAQ_00_22$year = as.numeric(format(DailyAQ_00_22$DATE, "%Y"))

DailyAQ_00_22_Yearly_Growth <- DailyAQ_00_22 %>%
  group_by(year) %>%
  summarize(pm2.5_total = sum(PM2.5, na.rm=T),
            pm2.5_avg = mean(PM2.5, na.rm=T),
            aqi_total = sum(AQI, na.rm=T),
            aqi_avg = mean(AQI, na.rm=T))

DailyAQ_00_22_Yearly_Growth <- DailyAQ_00_22_Yearly_Growth %>%
  mutate(pm2.5_diffRate = 
              ((pm2.5_total - lag(pm2.5_total, default = 0)) / pm2.5_total) * 100,
         aqi_diffRate = 
          ((aqi_total - lag(aqi_total, default = 0)) / aqi_total) * 100
      )

# remove first year data
DailyAQ_00_22_Yearly_Growth <- DailyAQ_00_22_Yearly_Growth[-1,]

```

We have about 7,000 observations between the years 2000 and 2022. A few plots to help us visualize the data:  

```{r daily aqi plots}
# distribution plot of pmi2.5 and daily AQI
mean_pm25 <- mean(DailyAQ_00_22$PM2.5)
mean_aqi <- mean(DailyAQ_00_22$AQI)

ggplot(DailyAQ_00_22) +
  geom_histogram(aes(x=PM2.5), na.rm=TRUE, alpha=0.5, color="black", fill='#BD2AE2', bins=100, binwidth=2) +
  geom_vline(xintercept=mean_pm25, color="black", size=1, linetype=5, show.legend=FALSE) +
  annotate("text", x=mean_pm25 + 9, y=1000, label=paste(round(mean_pm25, 2)), angle=0, size=4, color="black") +
  labs(title="Distribution of Daily PM2.5 Measurements", x="ug/m3 LC", y="Count")

ggplot(DailyAQ_00_22) +
  geom_histogram(aes(x=AQI), na.rm=TRUE, alpha=0.5, color="black", fill='#2DD164', bins=50, binwidth=5) +
  geom_vline(xintercept=mean_aqi, color="black", size=1, linetype=5, show.legend=FALSE) +
  annotate("text", x=mean_aqi + 9, y=625, label=paste(round(mean_aqi, 2)), angle=0, size=4, color="black") +
  labs(title="Distribution of Daily AQI Level", x="", y="Count")


# yearly average and year-over year growth of daily AQI and PM2.5
# TODO: combine plots into one frame
ggplot(DailyAQ_00_22_Yearly_Growth, aes(group=1)) +
  geom_line(aes(x = year, y = pm2.5_avg), stat="identity", color="#BD2AE2", size=1) +
  geom_line(aes(x = year, y = pm2.5_diffRate), stat="identity", color="#290DDA", size=1) +
  labs(title="Yearly average amount of PM2.5 particulates in atmosphere and growth rate", x="Year", y="ug/m3 LC") +
  scale_y_continuous(sec.axis = sec_axis(~., name="Year-over-year Diff (%)")) +
  theme(
    axis.title.y = element_text(color = "#BD2AE2", size = 13),
    axis.title.y.right = element_text(color = "#290DDA", size = 13)
  )

ggplot(DailyAQ_00_22_Yearly_Growth, aes(group=1)) +
  geom_line(aes(x = year, y = aqi_avg), stat="identity", color="#2DD164", size=1) +
  geom_line(aes(x = year, y = aqi_diffRate), stat="identity", color="#457108", size=1) +
  labs(title="Yearly average amount of PM2.5 particulates in atmosphere and growth rate", x="Year", y="ug/m3 LC") +
  scale_y_continuous(sec.axis = sec_axis(~., name="Year-over-year Diff (%)")) +
  theme(
    axis.title.y = element_text(color = "#2DD164", size = 13),
    axis.title.y.right = element_text(color = "#457108", size = 13)
  )

```

Next, we will combine our new dataset with the NYC weather data based on the date. Since there are a few missing dates in the air quality data, we will simply drop those rows without a air quality measurement.  
 
```{r combine and clean data}
# merge data frame by date
DailyAQ_merged <- merge(DailyAQ_00_22, NYweath_00, by="DATE")
# select required columns
DailyAQ_merged <- DailyAQ_merged[ , c('DATE', 'year.x', 'month', 'PM2.5', 'AQI', 'TMAX', 'TMIN', 'PRCP', 'SNOW')]
colnames(DailyAQ_merged)[2] <- "year"
str(DailyAQ_merged)
xkablesummary(DailyAQ_merged)

```


### Linear Model with daily air quality and weather variables

Run correlation analysis on continuous numerical variables:
    - TMAX, TMIN, PRCP, SNOW? (combine with PRCP?)  
    - AQI, PM25  
    - correlation plot and scatter plots of significant relationships.  
    - is local air quality correlated to local weather patterns?  

```{r correlation analysis}
# subset to numerical variables
DailyAQ_numerics <- DailyAQ_merged[ , c('PM2.5', 'AQI', 'TMAX', 'TMIN', 'PRCP', 'SNOW')]
# add PRCP and SNOW into single value
DailyAQ_numerics$PRCP <- DailyAQ_numerics$PRCP + DailyAQ_numerics$SNOW
DailyAQ_numerics <- subset(DailyAQ_numerics, select = -c(SNOW))
DailyAQ_cor <- cor(DailyAQ_numerics)
corrplot.mixed(DailyAQ_cor)
```

From the pearson correlation plot above, we can see a significantly large, positive correlation between PM2.5 concentrations and the daily air quality index. Unfortunately, The correlations among our weather and air quality variables is relatively weak.  

We can visualize a few correlation using a scatter plot:
```{r scatter correlations}
```

Build linear regression model
    1. Describe significance and functions  
    2. calculate VIF factor  
    3. Evaluate fit and plot line on scatter   
  
Let's start by creating a linear model to describe the relationship between AQI and the rest of the numeric variables.

```{r linear model}
aqi_fit <- lm(AQI ~ PM2.5 + TMAX + PRCP, data = DailyAQ_numerics)
xkabledply(aqi_fit, title = paste("Model :", format( formula(aqi_fit) )))
# model VIF scores
xkablevif(aqi_fit)
```


Add month as a categorical regressor and build another model
    1. Repeat steps 1-3 from above  
    2. If significant, compare with first model via ANOVA (if that is also significant).  

```{r second linear model}
```

Try Ridge on model with best fit?  

### k-NN model to predict month based on weather and air quality data

Evaluate relationships via scatter plots
  - scale and center data  
  - scatter plots of AQI,PM25,TMAX,TMIN,PRCP colored by month  
  - check composition of labels (months)  
  
```{r scatter plots}
```

Run k-NN model
  - Evaluate model accuracy, precision, (others?)
  - cross validation to find best `k` value
