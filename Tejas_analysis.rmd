---
title: "Project 2 EDA"
author: "Tejas Rawal"
date: "`r Sys.Date()`"
output:
  html_document:
    code_folding: hide
    number_sections: false
    toc: yes
    toc_depth: 3
    toc_float: yes
  pdf_document:
    toc: yes
    toc_depth: '3'
---

```{r include=FALSE}
# The package "ezids" (EZ Intro to Data Science) includes a lot of the helper functions we developed for the course. 
# Some of the frequently used functions are loadPkg(), xkabledply(), xkablesummary(), uzscale(), etc.
library(ezids)
 
# some of common options (and the defaults) are: 
# include=T, eval=T, echo=T, results='hide'/'asis'/'markup',..., collapse=F, warning=T, message=T, error=T, cache=T, fig.width=6, fig.height=4, fig.dim=c(6,4) #inches, fig.align='left'/'center','right', 
# knitr::opts_chunk$set(warning = F, results = "markup", message = F)
knitr::opts_chunk$set(warning = F, results = "markup", message = F)
options(scientific=T, digits = 3) 
# options(scipen=9, digits = 3) 
# ‘scipen’: integer. A penalty to be applied when deciding to print numeric values in fixed or exponential notation.  Positive values bias towards fixed and negative towards scientific notation: fixed notation will be preferred unless it is more than ‘scipen’ digits wider.
# use scipen=999 to prevent scientific notation at all times
```

```{r data init}
#loading packages 
library(ezids)
#library(ggplot2)
library(ggrepel)
library(gridExtra)
#library(tibble)
library(tidyverse)
library(corrplot)
library(lattice)
library(psych)
library(FNN)
library(caret)
library(pROC)

#loading data 
NYweath <- data.frame(read.csv("data/NYC_weather_1869_2022.csv"))

#converting to R date format and adding columns for day, month, and year
NYweath$DATE <- as.Date(NYweath$DATE)
NYweath$day <- format(NYweath$DATE, format="%d")
NYweath$month <- format(NYweath$DATE, format="%m")
NYweath$year <- format(NYweath$DATE, format="%Y")

#converting temperature observations to numerical
NYweath$TMAX <- as.numeric(NYweath$TMAX)
NYweath$TMIN <- as.numeric(NYweath$TMIN)
NYweath$TAVG <- as.numeric(NYweath$TAVG)
NYweath$year <- as.numeric(NYweath$year)

#Making month a factor
NYweath$month <- as.factor(NYweath$month)

# subset data to desired variables
NYweath_sub <- subset(NYweath, select = c(DATE, day, month, year, TMAX, TMIN, TAVG, PRCP, SNOW)) 

#creating a subset for 1900 on
NYweath_00 <- subset(NYweath_sub, year > 1899)
xkabledplyhead(NYweath_00)
```

# Are there statistically measurable changes in NYC air quality over time, and are they correlated to changes in daily maximum temperature observed in previous analysis?

## Analysis Questions

1. Logistic regression to predict rainy day based on TMAX, TMIN, MONTH, DAY?  
2. Linear correlations between Air Quality, time, and maximum temperature
3. Can we predict the month based on daily air quality and maximum temperature (kNN)?  

### Logitic Model Preparation

First, we format our data to create a variable representing whether it rained on a given day, starting :

```{r rainy days data}
# add column based on condition of rain on a given day
NYweath.rain <- NYweath_00
NYweath.rain$rained <- ifelse(NYweath.rain$PRCP > 0.0, 1, 0)
NYweath.rain$rained <- as.factor(NYweath.rain$rained)
xkablesummary(NYweath.rain)
xkabledplyhead(NYweath.rain)
```

First, let's create a two-way contingency table To study the effects on rainy day by the factor month and make sure there are no cells of zero frequencies.  

```{r crosstable}
rainy_vs_month = xtabs(~ rained + month, data = NYweath.rain)
rainy_vs_month
```

We can then quickly run a chi-squared test to see if the two are independent (or same frequency distribution).  
```{r chisq}
chisq.result = chisq.test(rainy_vs_month)
chisq.result
```

Based on the result, the factor variables `rained` and `month` are dependent - there is a statistically significant relationship between the two. We can use the `month` variable in our logistic regression to predict the `rained` outcome for a day. 

### The Logistic Model

Let's jump to the logistic regression to predict a precipitation event on a given day:

```{r logit attempt}
rainedLogit <- glm(rained ~ month + TMAX + TMIN, data = NYweath.rain, family = "binomial")
summary(rainedLogit)
xkabledply(rainedLogit, title = paste("Logistic Regression :", format(formula(rainedLogit)) ))
```

All the coefficients are found significant (small p-values) except for the months of February, March, and April. TMAX has a negative effect on precipitation while TMIN has a positive effect. The months with significant coefficients all have a negative effect on the rain outcome for a given day.

Let's obtain the growth/decay factors for each explanatory variables. The factors are the exponentials of the coefficients:   

```{r growthDecayFactors, results='markup', collapse=F}
expcoeff = exp(coef(rainedLogit))
xkabledply(as.table(expcoeff), title = "Exponential of coefficients in rained Logit Reg")
```

Compared to January, the months of February and March have a positive effect on the probability of a rainy day. Each gain in the minimum daily temperature value also has a positive effect on chances of rain.  

### Logistic Model Evaluation

#### Confusion matrix
```{r logit confusion matrix}
library(ModelMetrics)
library(scales)

rainedLogit.confusion <- ModelMetrics::confusionMatrix(
  actual = rainedLogit$y,
  predicted = rainedLogit$fitted.values)

xkabledply(rainedLogit.confusion,
  title = "Confusion matrix for logit model")

accuracy <- (rainedLogit.confusion[4] + rainedLogit.confusion[1]) / nrow(NYweath.rain)
precision <- rainedLogit.confusion[4] / (rainedLogit.confusion[4] + rainedLogit.confusion[3])
```

The confusion matrix above was generated for the cutoff value of `0.5`.  

The accuracy of this logistic model is approx. `r format(accuracy, format = "f", digits = 2)` which shows that out of all predictions made by our model on whether it rained or not, `r format(100 * accuracy, format= "f", digits = 2)`% were correct.  

The precision value signals that it actually only rained on `r format(100 * precision, format= "f", digits = 2)`% of the days out of all days the model predicted it would rain.    

#### Mcfadden's Test
```{r logit mcfadden test}
rainedNullLogit <- glm(rained ~ 1, data = NYweath.rain, family = "binomial")
mcFadden = 1 - logLik(rainedLogit)/logLik(rainedNullLogit)
mcFadden
```

The McFadden test outputs a pseudo-R-square value of `r mcFadden[1]` which demonstrates that only about `r format(100 * mcFadden[1], format= "f", digits = 2)`% of the variation in rainy day outcomes is explained by our regressors. This is not a significant outcome for the likelihood that the model is correct at predicting rainy days.  

#### Hosmer and Lemeshow test  

The Hosmer and Lemeshow Goodness of Fit test can be used to evaluate logistic regression fit. 

```{r HosmerLemeshow}
library(ResourceSelection)
# Hosmer and Lemeshow test, a chi-squared test
rainedLogitHoslem = hoslem.test(NYweath.rain$rained, fitted(rainedLogit))
rainedLogitHoslem
```

The p-value of `r rainedLogitHoslem$p.value` is very low which indicates that the model is a good fit.

#### ROC/AUC
```{r titanic logic roc/auc}
library(pROC)
probabilities <- predict(rainedLogit, type = "response")
# add probabilities as column
NYweath.rain$probs <- probabilities

rainedLogitROC <- roc(rained~probs, data=NYweath.rain)
plot(rainedLogitROC)
```

The area-under-curve of the ROC plot is `r format(rainedLogitROC$auc[1], digits = 2)`, which is less than the significance value of 0.8. The true positive rate of our model measure is about `r format(rainedLogitROC$auc[1] * 100, digits = 2)`%.  

Overall, I think we should attempt to find a different combination of predictors for this model.  

## NYC daily air quality data analysis

Let's pull in our air quality data. It contains measurements of daily PM2.5 and air quality index values taken from various locations around Manhattan.  

PM2.5 includes particles less than or equal to 2.5 micrometers and is also called fine particle pollution. The AQI is an index for reporting daily air quality. It tells how clean or polluted the air is, and what associated health effects might be a concern, especially for ground-level ozone and particle pollution.


Let's load the new data and have a look at it's structure:
```{r load csvs}
DailyAQ_00_22 <- data.frame(read.csv("data/daily-AQ-NY-00-20.csv"))
DailyAQ_00_22 <- DailyAQ_00_22[c('Date', 'Daily.Mean.PM2.5.Concentration', 'DAILY_AQI_VALUE')]
colnames(DailyAQ_00_22) <- c('DATE', 'PM2.5', 'AQI')
str(DailyAQ_00_22)
xkablesummary(DailyAQ_00_22)
xkabledplyhead(DailyAQ_00_22)
```

We need to convert the date from a character string to an R type. We also calculate year-over-year growth rates for both daily PM2.5 and AQI and store them in a column.

```{r formatting, echo = F}
DailyAQ_00_22$DATE <- as.Date(DailyAQ_00_22$DATE, "%m/%d/%y")

DailyAQ_00_22$year = as.numeric(format(DailyAQ_00_22$DATE, "%Y"))

DailyAQ_00_22_Yearly_Growth <- DailyAQ_00_22 %>%
  group_by(year) %>%
  summarize(pm2.5_total = sum(PM2.5, na.rm=T),
            pm2.5_avg = mean(PM2.5, na.rm=T),
            aqi_total = sum(AQI, na.rm=T),
            aqi_avg = mean(AQI, na.rm=T))

DailyAQ_00_22_Yearly_Growth <- DailyAQ_00_22_Yearly_Growth %>%
  mutate(pm2.5_diffRate = 
              ((pm2.5_avg - lag(pm2.5_avg)) / pm2.5_avg) * 100,
         aqi_diffRate = 
          ((aqi_avg - lag(aqi_avg)) / aqi_avg) * 100
      )

```

We have about 7,000 observations between the years 2000 and 2022. A few plots to help us visualize the data:  

```{r daily aqi plots}
# distribution plot of pmi2.5 and daily AQI
mean_pm25 <- mean(DailyAQ_00_22$PM2.5)
mean_aqi <- mean(DailyAQ_00_22$AQI)

# TODO: combine plots into one frame
ggplot(DailyAQ_00_22) +
  geom_histogram(aes(x=PM2.5), na.rm=TRUE, alpha=0.5, color="black", fill='#BD2AE2', bins=100, binwidth=2) +
  geom_vline(xintercept=mean_pm25, color="black", size=1, linetype=5, show.legend=FALSE) +
  annotate("text", x=mean_pm25 + 9, y=1000, label=paste(round(mean_pm25, 2)), angle=0, size=4, color="black") +
  labs(title="Distribution of Daily PM2.5 Measurements", x="ug/m3 LC", y="Count")

ggplot(DailyAQ_00_22) +
  geom_histogram(aes(x=AQI), na.rm=TRUE, alpha=0.5, color="black", fill='#2DD164', bins=50, binwidth=5) +
  geom_vline(xintercept=mean_aqi, color="black", size=1, linetype=5, show.legend=FALSE) +
  annotate("text", x=mean_aqi + 9, y=625, label=paste(round(mean_aqi, 2)), angle=0, size=4, color="black") +
  labs(title="Distribution of Daily AQI Level", x="", y="Count")


# TODO: group these in same figure, separate plots
ggplot(DailyAQ_00_22_Yearly_Growth, aes(group=1)) +
  geom_line(aes(x = year, y = pm2.5_diffRate), na.rm = T, stat = "identity", color="#290DDA", size=1) +
  geom_point(aes(x = year, y = pm2.5_diffRate), na.rm = TRUE, fill="#124CF2", shape = 23) +
  labs(title="PM2.5 particulate year-over-year rate in NYC", x="Year", y="ug/m3 LC") +
  theme(
    axis.title.y = element_text(color = "#043008", size = 13),
    axis.title.y.right = element_text(color = "#E6E930", size = 13)
  )

ggplot(DailyAQ_00_22_Yearly_Growth, aes(group=1)) +
  geom_line(aes(x = year, y = aqi_diffRate), na.rm = T, stat="identity", color="#043008", size=1) +
  geom_point(aes(x = year, y = aqi_diffRate), na.rm = TRUE, fill="#E6E930", shape = 23) +
  labs(title="AQI year-over-year rate in NYC", x="Year", y="ug/m3 LC") +
  theme(
    axis.title.y = element_text(color = "#043008", size = 13),
    axis.title.y.right = element_text(color = "#E6E930", size = 13)
  )
```

Next, we combine our new dataset with the NYC weather data based on the date. The days without a matching air quality measurement will be dropped after merge.
 
```{r combine and clean data}
# merge data frame by date
DailyAQ_merged <- merge(DailyAQ_00_22, NYweath_00, by="DATE")
# select required columns
DailyAQ_merged <- DailyAQ_merged[ , c('DATE', 'year.x', 'month', 'PM2.5', 'AQI', 'TMAX', 'TMIN', 'PRCP', 'SNOW')]
colnames(DailyAQ_merged)[2] <- "year"
str(DailyAQ_merged)
xkablesummary(DailyAQ_merged)

```


### Linear Model with daily air quality and weather variables

```{r data prep}
# subset to numerical variables
DailyAQ_numerics <- DailyAQ_merged[ , c('PM2.5', 'AQI', 'TMAX', 'TMIN', 'PRCP', 'SNOW', 'year')]
# combine PRCP and SNOW into single value
#DailyAQ_numerics$PRCP <- DailyAQ_numerics$PRCP + DailyAQ_numerics$SNOW
#DailyAQ_numerics <- subset(DailyAQ_numerics, select = -c(SNOW))
DailyAQ_numerics$year <- DailyAQ_numerics$year - 2000 
```

#### Correlation analysis

Lattice pairs plot

```{r pairs}
pairs(DailyAQ_numerics)
pairs.panels(DailyAQ_numerics, 
  method = "pearson", # correlation method
  hist.col = "red", # set histogram color
  density = TRUE,  # show density plots
  ellipses = TRUE, # show correlation ellipses
  smoother = TRUE,
  lm = TRUE,
  main = "Pairs Plot Of Weather and Air Quality Numerical Variables",
  cex.labels=0.75
)
```
Another way to look at correlation using the `corrplot` function:

```{r corrplot, fig.align = 'center'}
DailyAQ_cor <- cor(DailyAQ_numerics)
corrplot(DailyAQ_cor, method="number", title="Correlation Plot Of Weather and Air Quality Numerical Variables", mar = c(2, 2, 2, 2))
```

From the pearson correlation plot above, we can see a significantly large, positive correlation between PM2.5 concentrations and the daily AQI values. This is expected as PM2.5 are heavily weighed in calculations of AQI. Unfortunately, the correlation significance among our weather and air quality variables is relatively weak. However, we will still attempt a linear model between them below.   

```{r AQI and PM2.5 vs year}
# yearly average and year-over year growth of daily AQI and PM2.5
ggplot(DailyAQ_00_22_Yearly_Growth) +
  geom_line(aes(x = year, y = aqi_avg), stat="identity", color="#2DD164", size=1) +
  geom_point(aes(x = year, y = aqi_avg), na.rm = TRUE, fill="#457108", shape = 21) +
  labs(title="Average AQI by year in NYC", x="Year", y="AQI value")

ggplot(DailyAQ_00_22_Yearly_Growth) +
  geom_line(aes(x = year, y = pm2.5_avg), stat="identity", color="#BD2AE2", size=1) +
  geom_point(aes(x = year, y = pm2.5_avg), na.rm = TRUE, fill="#124CF2", shape = 21) +
  labs(title="Average PM2.5 particulate amount by year in NYC", x="Year", y="Year-over-year Diff (%)")
```

#### Linear models

Let's start by creating a linear model to describe the relationship between AQI and year.

```{r linear model}
aqi_fit <- lm(AQI ~ year, data = DailyAQ_numerics)
summary(aqi_fit)
xkabledply(aqi_fit, title = paste("First Linear Model: ", format( formula(aqi_fit) )))
```

The coefficient for the year regressor is significant, and has a negative effect on daily AQI by a very small factor of 1.77. Although the p-value of the F-statistic is significant, year still only explains 28% of the variability in daily AQI measurements.  

```{r lm plot}
ggplot(DailyAQ_00_22, aes(x = year, y = AQI)) + 
  geom_point(alpha = 0.5, color = "#2DD164", position = "jitter") +
  labs(x = "Year", y = "AQI Value", title = "Daily AQI Values From 2000-2022 With Trend Line") +
  geom_smooth(method = 'lm', formula = 'y ~ x', color = "black", fill="black")
```

The plot displays a slightly downward treng in daily AQI, but there is a lot of noise distorting the fit.

##### Adding `month` as a categorical regressor
In our first analysis, we analyzed linear trends of TMAX over time and determined a slight positive correlation observed over the years 1900-2022. Based on that fit, we hypothesized that seasonality trends had an impact on model performance.

We believe seasonality also effects daily AQI measurements. 

```{r average AQI and TMAX vs year}
# NYC weather - Avg TMAX by month
NYweath_Monthly_Avg <- NYweath_00 %>%
  group_by(month) %>%
  summarize(avg_max_temp = mean(TMAX, na.rm=T),
            avg_min_temp = mean(TMIN, na.rm=T))


ggplot(NYweath_Monthly_Avg, aes(x = as.numeric(month), y = avg_max_temp)) +
  geom_line(color="#F21E1E", size = 2) +
  geom_point(na.rm = TRUE, fill="#126BF4", shape = 21, size = 4) +
  labs(title="Average TMAX By Month in NYC", x="Month", y="Temperature (°F)") +
  scale_x_continuous(name = "Month",
                     breaks = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12))


DailyAQ_monthly <- DailyAQ_merged %>%
  group_by(month) %>%
  summarize(pm2.5_avg = mean(PM2.5, na.rm=T),
            aqi_avg = mean(AQI, na.rm=T))

# calculate growth/decay rates month-over-month
DailyAQ_monthly <- DailyAQ_monthly %>%
  mutate(pm2.5_diffRate = ((pm2.5_avg - lag(pm2.5_avg)) / pm2.5_avg) * 100,
         aqi_diffRate = ((aqi_avg - lag(aqi_avg)) / aqi_avg) * 100
      )
# populate January rates based on December
DailyAQ_monthly[1, 4]$pm2.5_diffRate <- ((DailyAQ_monthly$pm2.5_avg[1] - DailyAQ_monthly$pm2.5_avg[12]) /  DailyAQ_monthly$pm2.5_avg[1]) * 100
DailyAQ_monthly[1, 5]$aqi_diffRate <- ((DailyAQ_monthly$aqi_avg[1] - DailyAQ_monthly$aqi_avg[12]) /  DailyAQ_monthly$aqi_avg[1]) * 100

# yearly average and year-over year growth of daily AQI and PM2.5
# TODO: combine with month-over-month change plot
ggplot(DailyAQ_monthly, aes(x = as.numeric(month), y = aqi_avg)) +
  geom_line(color="#47ABE9", size = 2) +
  geom_point(na.rm = TRUE, fill="#C10808", shape = 21, size = 4) +
  labs(title="Average AQI By Month in NYC", x="Month", y="AQI") +
  scale_x_continuous(name = "Month",
                     breaks = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12))


ggplot(DailyAQ_monthly, aes(x = as.numeric(month), y = aqi_diffRate)) +
  geom_line(na.rm = TRUE, stat="identity", color="#043008", size=2) +
  geom_point(na.rm = TRUE, fill="#E6E930", shape = 21) +
  labs(title="Average AQI month-over-month change rate", x="Month", y="AQI") +
  scale_x_continuous(name = "Month",
                     breaks = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12))
```

Let's modify our last model to attempt to fit seasonality by adding `month` as a categorical regressor and our variable-of-interest from the last project - `TMAX` - to predict daily AQI.

```{r second linear model}
aqi_fit2 <- lm(AQI ~ TMAX + month, data = DailyAQ_merged)
summary(aqi_fit2)
xkabledply(aqi_fit2, title = paste("Second Linear Model: ", format( formula(aqi_fit2) )))
```

The regression coefficient for TMAX is significant and positively correlated, with each degree increase resulting in AQI increasing by a factor of 0.68. All months, when compared to January, have a negative impact on AQI, with September having the largest difference. The p-value of the model's F-statistic is also significant, allowing us to reject the null hypothesis and conclude that there’s a significant relationship between our chosen predictors and the daily AQI value. However, the $R^2$ for our model is only `.149`, which indicates that only 14.7% of the variation in daily AQI can be explained by TMAX and month.  

Seasonality can cause a poor linear model. Properly testing it would require developing a seasonality time-series model to properly fit the data.

Check for multicollinearity

```{r model 1 VIF, }
# model VIF scores
xkablevif(aqi_fit2, title = "Model 2 VIF")
```

The VIF values of all regressors are acceptable.  


### k-NN model to predict month based on weather and air quality data

A k-NN model can help us further analyze the seasonality effect by attempting to predict the month based on `AQI` and `TMAX` variables.  

Evaluate relationships via scatter plots
  - scale and center data  
  - scatter plots of AQI,TMAX  
  - check composition of labels (months) 
  
Plot variables
  
```{r scatter plots, fig.width=4, fig.height=2}
ggplot(DailyAQ_merged) +
    geom_point(aes(x=AQI, y=TMAX, color=month), alpha = 0.7) +
    labs(title = "Daily Maximum Temperature vs Daily Air Quality Index Value Distinguished By Month",
         x = "Daily AQI Value",
         y = "Daily Maximum Temperature (F)") +
  scale_color_brewer(palette = "Paired")
```

Center and scale our data

```{r normalize data}
DailyAQ_knn <- subset(DailyAQ_merged, select = c(month, TMAX, AQI))
DailyAQ_scaled <- as.data.frame(scale(DailyAQ_knn[2:3], center = TRUE, scale = TRUE))
str(DailyAQ_scaled)
```

Create train and test data sets with 4:1 splits, as well as label sets.

```{r train/test splits}
set.seed(1000)
DailyAQ_sample <- sample(2, nrow(DailyAQ_scaled), replace=TRUE, prob=c(0.80, 0.20))

DailyAQ_training <- DailyAQ_scaled[DailyAQ_sample == 1, ]
DailyAQ_test <- DailyAQ_scaled[DailyAQ_sample == 2, ]

DailyAQ_trainLabels <- DailyAQ_knn[DailyAQ_sample == 1, 1]
DailyAQ_testLabels <- DailyAQ_knn[DailyAQ_sample == 2, 1]

str(DailyAQ_training)
str(DailyAQ_test)
```

How does *k* affect classification accuracy?

```{r evaluate for range of k}
evaluateK = function(k, train_set, val_set, train_class, val_class){
  
  # Build knn with k neighbors considered.
  set.seed(1000)
  class_knn = knn(train = train_set,    #<- training set cases
                  test = val_set,       #<- test set cases
                  cl = train_class,     #<- category for classification
                  k = k)                #<- number of neighbors considered
  
  tab = table(class_knn, val_class)
  
  # Calculate the accuracy.
  accu = sum(tab[row(tab) == col(tab)]) / sum(tab)                         
  cbind(k = k, accuracy = accu)
}

# call evaluateK function for each odd k-value between 1 to 21
knn_different_k = sapply(seq(1, 21, by = 2),
                         function(x) evaluateK(x, 
                                             train_set = DailyAQ_training,
                                             val_set = DailyAQ_test,
                                             train_class = DailyAQ_trainLabels,
                                             val_class = DailyAQ_testLabels))

# Reformat the results
knn_different_k = data.frame(k = knn_different_k[1,],
                             accuracy = knn_different_k[2,])
```

```{r accuracy vs k plot}
# TODO: Add ROC/AUC curve

xkabledply(knn_different_k, "Total Accuracy Summary")

# line plot of accuracy vs k-value
ggplot(knn_different_k, aes(x = k, y = accuracy)) +
  geom_line(color = "orange", size = 1.5) +
  geom_point(size = 3) + 
  labs(title = "kNN Model Accuracy vs k-value",
       x = "Model k-value",
       y = "Accuracy")

# model ROC/AUC

```

It seems 13-nearest neighbors is a decent choice because that's the greatest improvement in predictive accuracy before the incremental improvement trails off. With an accuracy of `r knn_different_k[7, 2]`, our model predicting month based on `TMAX` and `AQI` is not a strong fit.  

Build kNN model for k = 13
  
```{r kNN model}
# set kval
kval <- 13

# build model
DailyAQ_pred <- FNN::knn(train = DailyAQ_training,
                    test = DailyAQ_test,
                    cl = DailyAQ_trainLabels,
                    k = kval)

# confusion matrix
DailyAQ_confusionMatrix <- caret::confusionMatrix(DailyAQ_pred, reference = DailyAQ_testLabels)
DailyAQ_pred_accuracy <- DailyAQ_confusionMatrix$overall['Accuracy']


xkabledply(as.matrix(DailyAQ_confusionMatrix), title = paste("ConfusionMatrix for k = ", kval))
xkabledply(data.frame(DailyAQ_confusionMatrix$byClass), title=paste("k = ", kval))
```

Model ROC/AUC curve
```{r knn ROC/AUC}
# multiclass ROC on test labels
knnROC <- multiclass.roc(DailyAQ_testLabels, as.integer(DailyAQ_pred))
knnROC
```